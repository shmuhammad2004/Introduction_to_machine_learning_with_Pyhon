{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "## Chapter 8 : Wrapping Up\n",
    "### Approaching a machine learning problem\n",
    "\n",
    "- With all the great methods that we introduced in this book now at your fingertips, it may be tempting to jump in and start solving your data-related problem by just running your favorite algorithm <br><br>\n",
    "- However, this is not usually a good way to begin your analysis <br><br>\n",
    "- “The machine learning algorithm is usually only a small part of a larger data analysis and decision-making process.\n",
    "- To make effective use of machine learning, we need to take a step back and consider the problem at large. First, you should think about what kind of question you want to answer. Do you want to do exploratory analysis and just see if you find something interesting in the data? Or do you already have a particular goal in mind? <br><br>\n",
    "- Then the following questions open up: \n",
    "  - How do I measure if my fraud prediction is actually working? \n",
    "  - Do I have the right data to evaluate an algorithm? \n",
    "  - If I am successful, what will be the business impact of my solution?\n",
    "### Humans in the loop\n",
    "\n",
    "- You should also consider if and how you should have humans in the loop.  <br><br>\n",
    "- Some processes (like pedestrian detection in a self-driving car) need to make immediate decisions.  <br><br>\n",
    "- Others might not need immediate responses, and so it can be possible to have humans confirm uncertain decisions. <br><br>\n",
    "- Medical applications, for example, might need very high levels of precision that possibly cannot be achieved by a machine learning algorithm alone. <br><br>\n",
    "- But if an algorithm can make 90 percent, 50 percent, or maybe even just 10 percent of decisions automatically, that might already increase response time or reduce cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks\n",
    "\n",
    "- Recent breakthroughs in machine learning and artificial intelligence, such as the victory of the Alpha Go program against human champions in the game of Go, the constantly improving performance of speech understanding, and the availability of near-instantaneous speech translation, have all been driven by these advances. <br><br>\n",
    "- While the progress in this field is so fast-paced that any current reference to the state of the art will soon be outdated, the recent book Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville (MIT Press) is a comprehensive introduction into the subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing production systems\n",
    "\n",
    "- Thi book covered how to evaluate algorithmic predictions based on a test set that we collected beforehand.  <br><br>\n",
    "- This is known as ofline evaluation.  <br><br>\n",
    "- If your machine learning system is user-facing, this is only the first step in evaluating an algorithm.\n",
    "- The next step is usually online testing or live testing, where the consequences of employing the algorithm in the overall system are evaluated. \n",
    "- most user-facing services employ A/B testing, a form of blind user study<br><br>\n",
    "- In A/B testing, without their knowledge a selected portion of users will be provided with a website or service using algorithm A, while the rest of the users will be provided with algorithm B. <br><br>\n",
    "- For both groups, relevant success metrics will be recorded for a set period of time. Then, the metrics of algorithm A and algorithm B will be compared, and a selection between the two approaches will be made according to these metrics. <br><br>\n",
    "-  Using A/B testing enables us to evaluate the algorithms “in the wild,” which might help us to discover unexpected consequences when users are interacting with our model. Often A is a new model, while B is the established system. \n",
    "- There are more elaborate mechanisms for online testing that go beyond A/B testing, such as bandit algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where to go from here\n",
    "\n",
    "- This book provides an introduction to machine learning and will make you an effective practitioner. However, if you want to further your machine learning skills, here are some suggestions of books and more specialized resources to investigate to dive deeper.\n",
    "\n",
    "\n",
    "#### Theory\n",
    "-  Elements of Statistical Learning in the Preface, but it is worth repeating this recommendation here. <br><br>\n",
    "-  iMachine Learning: An Algorithmic Perspective by Stephen Marsland (Chapman and Hall/CRC). <br><br>\n",
    "-  Two other highly recommended classics are Pattern Recognition and Machine Learning by Christopher Bishop (Springer)<br><br>\n",
    "-  A Probabilistic Perspective by Kevin Murphy (MIT Press),\n",
    "#### Other machine learning frameworks and packages\n",
    "> If you are not married to Python, you might also consider using R, another lingua franca of data scientists. R is a language designed specifically for statistical analysis and is famous for its excellent visualization capabilities and the availability of many (often highly specialized) statistical modeling packages”\n",
    "> \n",
    "#### Ranking, recommender systems, time series, and other kinds of learning\n",
    "#### Probabilistic modeling, inference and probabilistic programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling to larger datasets\n",
    "- Always assumed that the data we were working with could be stored in a NumPy array or SciPy sparse matrix in memory (RAM). <br><br>\n",
    "- Even though modern servers often have hundreds of gigabytes (GB) of RAM, this is a fundamental restriction on the size of data you can work with. Some cannot affordd <br><br>\n",
    "- to process large amounts of data on a budget, there are two basic strategies: out-ofcore learning and parallelization over a cluster <br><br>\n",
    "- “Out-of-core learning describes learning from data that cannot be stored in main memory, but where the learning takes place on a single computer (or even a single processor within a computer) <br><br>\n",
    "- The data is read from a source like the hard disk or the network either one sample at a time or in chunks of multiple samples, so that each chunk fits into RAM. This subset of the data is then processed and the model is updated to reflect what was learned from the data.  <br><br>\n",
    "- Then, this chunk of the data is discarded and the next bit of data is read.   <br><br>\n",
    "- Out-of-core learning is implemented for some of the models in scikit-learn, and you can find details on it in the online  <br><br>user guide. \n",
    "- Because out-of-core learning requires all of the data to be processed by a single computer, this can lead to long runtimes on very large datasets. Also, not all machine learning algorithms can be implemented in this way.”  <br><br>\n",
    "- The other strategy for scaling is distributing the data over multiple machines in a compute cluster, and letting each computer process part of the data. This can be much faster for some models, and the size of the data that can be processed is only limited by the size of the cluster. However, such computations often require relatively complex infrastructure. One of the most popular distributed computing platforms at the moment is the spark platform built on top of Hadoop. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Honing your skills\n",
    "\n",
    "> “As with many things in life, only practice will allow you to become an expert in the topics we covered in this book. Feature extraction, preprocessing, visualization, and model building can vary widely between different tasks and different datasets. Maybe you are lucky enough to already have access to a variety of datasets and tasks. If you don’t already have a task in mind, a good place to start is machine learning competitions (Kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://repository-images.githubusercontent.com/439743567/e916cc40-0437-4735-ab72-68714f4c707f)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
