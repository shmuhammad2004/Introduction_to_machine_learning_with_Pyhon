{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to split already Split dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST dataset, which is a set of 70,000 small images of digits handwritten by high school students and employees of the US Census Bureau. Each image is labeled with the digit it represents. This set has been studied so much that it is often called the “Hello World” of Machine Learning: whenever people come up with a new classification algorithm, they are curious to see how it will perform on MNIST. Whenever someone learns Machine Learning, sooner or later they tackle MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scikit-Learn provides many helper functions to download popular datasets. MNIST is one of them\n",
    "# Fetch dataset from openml by name or dataset id.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "#Datasets are uniquely identified by either an integer ID or by a combination of name and version\n",
    "# openML : https://www.openml.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_openml.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return Databunch dictionary like Object\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets loaded by Scikit-Learn generally have a similar dictionary structure including:\n",
    "\n",
    "• A DESCR key describing the dataset \n",
    "\n",
    "• A data key containing an array with one row per instance and one column per feature\n",
    "\n",
    "• A target key containing an array with the labels Let’s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    ...  774  775  776  \\\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "69995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "       777  778  779  780  781  782  783  \n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "69995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "69996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "69997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "69998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "69999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[70000 rows x 784 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '0', '4', ..., '4', '5', '6'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      5\n",
       "1      0\n",
       "2      4\n",
       "3      1\n",
       "4      9\n",
       "...   ..\n",
       "69995  2\n",
       "69996  3\n",
       "69997  4\n",
       "69998  5\n",
       "69999  6\n",
       "\n",
       "[70000 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 70,000 images, and each image has 784 features. This is because each image is 28×28 pixels, and each feature simply represents one pixel’s intensity, from 0 (white) to 255 (black). Let’s take a peek at one digit from the dataset. All you need to do is grab an instance’s feature vector, reshape it to a 28×28 array, and display it using Matplotlib’s imshow() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   3.,  18.,\n",
       "        18.,  18., 126., 136., 175.,  26., 166., 255., 247., 127.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        30.,  36.,  94., 154., 170., 253., 253., 253., 253., 253., 225.,\n",
       "       172., 253., 242., 195.,  64.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  49., 238., 253., 253., 253., 253.,\n",
       "       253., 253., 253., 253., 251.,  93.,  82.,  82.,  56.,  39.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        18., 219., 253., 253., 253., 253., 253., 198., 182., 247., 241.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  80., 156., 107., 253.,\n",
       "       253., 205.,  11.,   0.,  43., 154.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  14.,   1., 154., 253.,  90.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       139., 253., 190.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  11., 190., 253.,  70.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  35., 241., 225., 160., 108.,   1.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  81., 240.,\n",
       "       253., 253., 119.,  25.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  45., 186., 253., 253., 150.,  27.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  16.,  93., 252., 253., 187.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 249., 253.,\n",
       "       249.,  64.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  46., 130., 183., 253., 253., 207.,   2.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  39., 148., 229., 253., 253., 253.,\n",
       "       250., 182.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  24., 114.,\n",
       "       221., 253., 253., 253., 253., 201.,  78.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  23.,  66., 213., 253., 253., 253., 253., 198.,  81.,\n",
       "         2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  18., 171., 219., 253., 253.,\n",
       "       253., 253., 195.,  80.,   9.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  55.,\n",
       "       172., 226., 253., 253., 253., 253., 244., 133.,  11.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0., 136., 253., 253., 253., 212., 135.,\n",
       "       132.,  16.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit = X[0] \n",
    "some_digit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   3.,  18.,  18.,  18., 126., 136., 175.,  26., 166., 255.,\n",
       "        247., 127.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  30.,  36.,  94.,\n",
       "        154., 170., 253., 253., 253., 253., 253., 225., 172., 253., 242.,\n",
       "        195.,  64.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,  49., 238., 253., 253.,\n",
       "        253., 253., 253., 253., 253., 253., 251.,  93.,  82.,  82.,  56.,\n",
       "         39.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,  18., 219., 253., 253.,\n",
       "        253., 253., 253., 198., 182., 247., 241.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  80., 156., 107.,\n",
       "        253., 253., 205.,  11.,   0.,  43., 154.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  14.,   1.,\n",
       "        154., 253.,  90.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        139., 253., 190.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         11., 190., 253.,  70.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,  35., 241., 225., 160., 108.,   1.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,  81., 240., 253., 253., 119.,  25.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,  45., 186., 253., 253., 150.,  27.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,  16.,  93., 252., 253., 187.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0., 249., 253., 249.,  64.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,  46., 130., 183., 253., 253., 207.,   2.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,  39., 148., 229., 253., 253., 253., 250., 182.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  24.,\n",
       "        114., 221., 253., 253., 253., 253., 201.,  78.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  23.,  66., 213.,\n",
       "        253., 253., 253., 253., 198.,  81.,   2.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,  18., 171., 219., 253., 253.,\n",
       "        253., 253., 195.,  80.,   9.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,  55., 172., 226., 253., 253., 253., 253.,\n",
       "        244., 133.,  11.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0., 136., 253., 253., 253., 212., 135., 132.,\n",
       "         16.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "some_digit_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAGaElEQVR4nO3dPUiWfR/G8dveSyprs2gOXHqhcAh6hZqsNRqiJoPKRYnAoTGorWyLpqhFcmgpEmqIIByKXiAHIaKhFrGghiJ81ucBr991Z/Z4XPr5jB6cXSfVtxP6c2rb9PT0P0CeJfN9A8DMxAmhxAmhxAmhxAmhljXZ/Vcu/H1tM33RkxNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCLZvvG+B//fr1q9y/fPnyVz9/aGio4fb9+/fy2vHx8XK/ceNGuQ8MDDTc7t69W167atWqcr948WK5X7p0qdzngycnhBInhBInhBInhBInhBInhBInhHLOOYMPHz6U+48fP8r92bNn5f706dOG29TUVHnt8PBwuc+nLVu2lPv58+fLfWRkpOG2du3a8tpt27aV+759+8o9kScnhBInhBInhBInhBInhBInhGqbnp6u9nJsVS9evCj3gwcPlvvffm0r1dKlS8v91q1b5d7e3j7rz960aVO5b9iwody3bt0668/+P2ib6YuenBBKnBBKnBBKnBBKnBBKnBBKnBBqUZ5zTk5Olnt3d3e5T0xMzOXtzKlm997sPPDx48cNtxUrVpTXLtbz3zngnBNaiTghlDghlDghlDghlDghlDgh1KL81pgbN24s96tXr5b7/fv3y33Hjh3l3tfXV+6V7du3l/vo6Gi5N3un8s2bNw23a9euldcytzw5IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IdSifJ/zT339+rXcm/24ut7e3obbzZs3y2tv375d7idOnCh3InmfE1qJOCGUOCGUOCGUOCGUOCGUOCHUonyf80+tW7fuj65fv379rK9tdg56/Pjxcl+yxL/HrcKfFIQSJ4QSJ4QSJ4QSJ4QSJ4Tyytg8+PbtW8Otp6envPbJkyfl/uDBg3I/fPhwuTMvvDIGrUScEEqcEEqcEEqcEEqcEEqcEMo5Z5iJiYly37lzZ7l3dHSU+4EDB8p9165dDbezZ8+W17a1zXhcR3POOaGViBNCiRNCiRNCiRNCiRNCiRNCOedsMSMjI+V++vTpcm/24wsrly9fLveTJ0+We2dn56w/e4FzzgmtRJwQSpwQSpwQSpwQSpwQSpwQyjnnAvP69ety7+/vL/fR0dFZf/aZM2fKfXBwsNw3b948689ucc45oZWIE0KJE0KJE0KJE0KJE0KJE0I551xkpqamyv3+/fsNt1OnTpXXNvm79M+hQ4fK/dGjR+W+gDnnhFYiTgglTgglTgglTgglTgjlKIV/beXKleX+8+fPcl++fHm5P3z4sOG2f//+8toW5ygFWok4IZQ4IZQ4IZQ4IZQ4IZQ4IdSy+b4B5tarV6/KfXh4uNzHxsYabs3OMZvp6uoq97179/7Rr7/QeHJCKHFCKHFCKHFCKHFCKHFCKHFCKOecYcbHx8v9+vXr5X7v3r1y//Tp02/f07+1bFn916mzs7PclyzxrPhvfjcglDghlDghlDghlDghlDghlDghlHPOv6DZWeKdO3cabkNDQ+W179+/n80tzYndu3eX++DgYLkfPXp0Lm9nwfPkhFDihFDihFDihFDihFDihFCOUmbw+fPncn/79m25nzt3rtzfvXv32/c0V7q7u8v9woULDbdjx46V13rla2753YRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQC/acc3JysuHW29tbXvvy5ctyn5iYmM0tzYk9e/aUe39/f7kfOXKk3FevXv3b98Tf4ckJocQJocQJocQJocQJocQJocQJoWLPOZ8/f17uV65cKfexsbGG28ePH2d1T3NlzZo1Dbe+vr7y2mbffrK9vX1W90QeT04IJU4IJU4IJU4IJU4IJU4IJU4IFXvOOTIy8kf7n+jq6ir3np6ecl+6dGm5DwwMNNw6OjrKa1k8PDkhlDghlDghlDghlDghlDghlDghVNv09HS1lyMwJ9pm+qInJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4Rq9iMAZ/yWfcDf58kJocQJocQJocQJocQJocQJof4DO14Dh4wBfawAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(some_digit_image, cmap=mpl.cm.binary, interpolation=\"nearest\") \n",
    "plt.axis(\"off\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a 5, and indeed that’s what the label tells us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the label is a string. We prefer numbers, so let’s cast y to integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y = y.astype(np.uint8)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set\n",
    "\n",
    "You should always create a test set and set it aside before inspecting the data closely. The MNIST dataset is actually already split into a training set (the first 60,000 images) and a test set (the last 10,000 images):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4],\n",
       "       [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape(2, 5)  # now x is 2-dimensional\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    ...  774  775  776  \\\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "69995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "       777  778  779  780  781  782  783  \n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "69995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "69996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "69997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "69998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "69999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[70000 rows x 784 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l_/499_8k_5387b9tz3wp5g8lg00000gn/T/ipykernel_30144/231905734.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The training set is already shuffled for us, which is good as this guarantees that all cross-validation folds will be similar (you don’t want one fold to be missing some dig‐ its). Moreover, some learning algorithms are sensitive to the order of the training instances, and they perform poorly if they get many similar instances in a row. Shuf‐ fling the dataset ensures that this won’t happen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Binary Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s simplify the problem for now and only try to identify one digit—for example, the number 5. This “5-detector” will be an example of a binary classifier, capable of distinguishing between just two classes, 5 and not-5. Let’s create the target vectors for this classification task:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == 5) \n",
    "\n",
    "y_test_5 = (y_test == 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, ...,  True, False, False])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False,  True, False])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_5 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us pick classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    ...  774  775  776  \\\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "59995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "59996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "59997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "59998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "59999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "       777  778  779  780  781  782  783  \n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "59995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "59996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "59997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "59998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "59999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[60000 rows x 784 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0       True\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "...      ...\n",
       "59995  False\n",
       "59996  False\n",
       "59997   True\n",
       "59998  False\n",
       "59999  False\n",
       "\n",
       "[60000 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier(random_state=42) \n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The SGDClassifier relies on randomness during training (hence the name “stochastic”). If you want reproducible results, you should set the random_state parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remember some_digit is 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Evaluating a classifier is often significantly trickier than evaluating a regressor. There are many performance measures available.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring Accuracy Using Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> The machine learning methods often fail to model the data because they learn particular features of the training set, that are not present in the test set. So these features are not representative and we are in a situation of Overfitting. It happens when the model fits too much of the training data, but it’s not able to generalize in new samples. There are many ways to address this issue, regularization, selection of the best hyperparameters, and K fold cross validation. We focus on this last  because it has a relevant role to have an impartial performance of the model. Simply splitting the data into training and test set doesn't allow to have a real idea of the model performance. You can say “Wow”, 90% of accuracy on the training set, but after you see 60% of test accuracy. Surely something is wrong. Let us discuss Hold-out vs K-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hold out\n",
    "\n",
    "The classical and old-fashioned approach consists of diving the dataset into 3 fixed subsets: the common choice is to use 60% for training, 20% for validation, and 20% for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, Holdout Method suffers from issues of high variance. This is because it is not certain which data points will end up in the validation set and the result might be entirely different for different sets ( the results can depend on a particular random choice for the pair of (train, validation) sets.)\n",
    "\n",
    "Also, partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# remember we already have our dataset split\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8035\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cl = DecisionTreeClassifier(\n",
    "    max_depth=10000, random_state=0, min_samples_split=4, max_features=11)\n",
    "\n",
    "cl.fit(X_train, y_train)\n",
    "y_pred = cl.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9682666666666667"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There are many ways to address the issue of Overfitting: regularization, selection of the best hyperparameters, and K fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hold-out method is good to use when you have a very large dataset, you’re on a time crunch, or you are starting to build an initial model in your data science project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold Cross Validation\n",
    "\n",
    "\n",
    "A solution to the problem of Hold-out a procedure called cross-validation (CV for short). A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called k-fold CV, the training set is split into k smaller sets \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a popular method because it is simple to understand and because it generally results in a less biased or less optimistic estimate of the model skill than other methods, such as a simple train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">K-Fold Cross Validation   (k-fold CV) : As there is never enough data to train your model, removing a part of it for validation poses a problem of underfitting. By reducing the training data, we risk losing important patterns/ trends in data set, which in turn increases error induced by bias. So, what we require is a method that provides ample data for training the model and also leaves ample data for validation. K Fold cross validation does exactly that.\n",
    "\n",
    "* A model is trained using k-1 of the folds as training data;\n",
    "\n",
    "* The resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=10 becoming 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](/Users/shamsuddeenmuhammad/Documents/Vscdoe/Introduction_to_machine_learning_with_Pyhon/images/k-fold.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](/Users/shamsuddeenmuhammad/Documents/Vscdoe/Introduction_to_machine_learning_with_Pyhon/images/3-fold.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. This approach can be computationally expensive, but does not waste too much data (as is the case when fixing an arbitrary validation set), which is a major advantage in problems where the number of samples is very small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  In K Fold Cross Validation, we split the dataset into k folds, k-1 to train the model and the remaining one to evaluate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The general procedure is as follows:\n",
    "\n",
    "    Shuffle the dataset randomly.\n",
    "    Split the dataset into k groups\n",
    "    For each unique group:\n",
    "        Take the group as a hold out or test data set\n",
    "        Take the remaining groups as a training data set\n",
    "        Fit a model on the training set and evaluate it on the test set\n",
    "        Retain the evaluation score and discard the model\n",
    "    Summarize the skill of the model using the sample of model evaluation scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More how on how to choose K : https://machinelearningmastery.com/k-fold-cross-validation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go back to our digit-5 example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let’s use the cross_val_score() function  to evaluate your SGDClassifier model using K-fold cross-validation, with three folds. Remember that K-fold cross-validation means splitting the training set into K-folds (in this case, three), then making predictions and evaluating them on each fold using a model trained on the remaining folds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95035, 0.96035, 0.9604 ])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Above 95% accuracy (ratio of correct predictions) on all cross-validation folds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Although, the most common metric used to evaluate the performance of a classification predictive model is classification accuracy. Typically, the accuracy of a predictive model is good (above 90% accuracy), therefore it is also very common to summarize the performance of a model in terms of the error rate of the model. But, Accuracy is not a good measure of implance datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Accuracy = Correct Predictions / Total Predictions </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which Metric to Use?\n",
    "Not Accuracy: Most of the time you will be dealing with imbalanced datasets and accuracy is not a good measure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Example: Lets assume 99% of one class (say apples) and 1% of another class is in your data set (say bananas). Our dump algorithm may get 99% accuracy for this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The confusion matrix provides more insight into not only the accuracy of a predictive model, but also which classes are being predicted correctly, which incorrectly, and what type of errors are being made.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "A much better way to evaluate the performance of a classifier is to look at the confusion matrix. Compute confusion matrix to evaluate the accuracy of a classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " sklearn.metrics.confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is a summary of the predictions made by a classification model organized into a table by class. Each row of the table indicates the actual class and each column represents the predicted class. A value in the cell is a count of the number of predictions made for a class that are actually for a given class. The cells on the diagonal represent correct predictions, where a predicted and expected class align.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](/Users/shamsuddeenmuhammad/Documents/Vscdoe/Introduction_to_machine_learning_with_Pyhon/images/confusion_matrix.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The most straightforward way to evaluate the performance of classifiers is based on the confusion matrix analysis. […] From such a matrix it is possible to extract a number of widely used metrics for measuring the performance of learning systems, such as Error Rate […] and Accuracy …"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the confusion matrix, you first need to have a set of predictions, so they can be compared to the actual targets. You could make predictions on the test set, but let’s keep it untouched for now (remember that you want to use the test set only at the very end of your project, once you have a classifier that you are ready to launch). Instead, you can use the cross_val_predict() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sgd_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l_/499_8k_5387b9tz3wp5g8lg00000gn/T/ipykernel_30144/2585103014.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgd_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_train_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sgd_clf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
    "y_train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Just like the cross_val_score() function, cross_val_predict() performs K-fold cross-validation, but instead of returning the evaluation scores, it returns the predic‐tions made on each test fold. This means that you get a clean prediction for each instance in the training set (“clean” meaning that the prediction is made by a model that never saw the data during training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to get the confusion matrix using the confusion_matrix() function. Just pass it the target classes (y_train_5) and the predicted classes (y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53892,   687],\n",
       "       [ 1891,  3530]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "cm = confusion_matrix(y_train_5, y_train_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use seaborn packagae to visualize our Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Seaborn : is a graphical representation of data using colors to visualize the value of the matrix.\n",
    "> #### more on sea : https://seaborn.pydata.org/generated/seaborn.heatmap.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data to be plotted:\n",
      "\n",
      "[[ 6 17 44 80 54 91 10 49 10 35]\n",
      " [57 49 99 10  5 46 79 60 29 85]\n",
      " [91 42 20 31 75  8 38 72 53 24]\n",
      " [97 74 17 15 44 59 12 98 36 74]\n",
      " [18 62 60 63 22 76 62 90  4 73]\n",
      " [65  1 41 32 47  8 45 34 12 61]\n",
      " [98 69 57 40 68 55 51 24  1 31]\n",
      " [64 28 42 56  6 27 44 28  1 17]\n",
      " [83 79 62 80 44 39 71 76 19 57]\n",
      " [81 26 77 38  3 27 86 18  3 51]]\n"
     ]
    }
   ],
   "source": [
    "# importing the modules\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "# generating 2-D 10x10 matrix of random numbers\n",
    "# from 1 to 100\n",
    "data = np.random.randint(low = 1,\n",
    "                         high = 100,\n",
    "                         size = (10, 10))\n",
    "print(\"The data to be plotted:\\n\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the heatmap\n",
    "hm = sn.heatmap(data = data)\n",
    "#hm = sn.heatmap(data = data, annot = True)\n",
    "\n",
    "# displaying the plotted heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===========================================\n",
    "- Coming back to our Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l_/499_8k_5387b9tz3wp5g8lg00000gn/T/ipykernel_30144/3921151410.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53892,   687],\n",
       "       [ 1891,  3530]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in this confusion matrix represents an actual class, while each column represents a predicted class. The first row of this matrix considers non-5 images (the negative class): 53892 of them were correctly classified as non-5s (they are called true negatives), while the remaining 687 were wrongly classified as 5s (false positives). \n",
    "\n",
    "The second row considers the images of 5s (the positive class): 1891 were wrongly classified as non-5s (false negatives), while the remaining 3530 were correctly classified as 5s (true positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perfect classifier would have only true positives and true negatives, so its confusion matrix would have nonzero values only on its main diagonal (top left to bottom right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54579,     0],\n",
       "       [    0,  5421]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretend we reached perfection >>> \n",
    "confusion_matrix(y_train_5, y_train_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix gives you a lot of information, but sometimes you may prefer a more concise metric. An interesting one to look at  are:\n",
    " - **precision** \n",
    " - **Recall**\n",
    "  \n",
    "Note : Both precision and recall are classification metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](/Users/shamsuddeenmuhammad/Documents/Vscdoe/Introduction_to_machine_learning_with_Pyhon/images/confu1.png)\n",
    "![](/Users/shamsuddeenmuhammad/Documents/Vscdoe/Introduction_to_machine_learning_with_Pyhon/images/confu2.png)\n",
    "![](/Users/shamsuddeenmuhammad/Documents/Vscdoe/Introduction_to_machine_learning_with_Pyhon/images/confu3.png)\n",
    "![](/Users/shamsuddeenmuhammad/Documents/Vscdoe/Introduction_to_machine_learning_with_Pyhon/images/confu4.png)\n",
    "![](/Users/shamsuddeenmuhammad/Documents/Vscdoe/Introduction_to_machine_learning_with_Pyhon/images/confu5.png)\n",
    "![](/Users/shamsuddeenmuhammad/Documents/Vscdoe/Introduction_to_machine_learning_with_Pyhon/images/confu6.png)\n",
    "![](/Users/shamsuddeenmuhammad/Documents/Vscdoe/Introduction_to_machine_learning_with_Pyhon/images/conf6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> with precision you can make sure that what you're saying is a positive actually is a positive but with recall you can make sure that you're not missing out on positive observations \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and Recall : https://www.youtube.com/watch?v=qWfzIYCvBqo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn provides several functions to compute classifier metrics, including preci‐ sion and recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8370879772350012"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score(y_train_5, y_train_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8370879772350012"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3530 / (687 + 3530)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6511713705958311"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train_5, y_train_pred)  # == 4096 / (4096 + 1325)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6511713705958311"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3530 / (3530+ 1891)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we put our focus into one score, we might end up neglecting the other. In order to combat this we can use the F1 Score, which strikes a balance between the Precision and Recall scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It is often convenient to combine precision and recall into a single metric called the F1 score, in particular if you need a simple way to compare two classifiers. The F1 score  is a measure of a model’s accuracy on a dataset. It is used to evaluate binary classification systems, which classify examples into ‘positive’ or ‘negative’. The F1 score is the harmonic mean of precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the diffrence betweeb Regular mean and Harmonic mean? Whereas the regular mean treats all values equally, the harmonic mean gives much more weight to low values. As a result, the classifier will only get a high F1 score if both recall and precision are\n",
    "high (https://en.wikipedia.org/wiki/Harmonic_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](/Users/shamsuddeenmuhammad/Documents/Vscdoe/Introduction_to_machine_learning_with_Pyhon/images/harmonic_mean.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](/Users/shamsuddeenmuhammad/Documents/Vscdoe/Introduction_to_machine_learning_with_Pyhon/images/f1_score.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the F1 score, simply call the f1_score() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7325171197343846"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score \n",
    "f1_score(y_train_5, y_train_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation metrics we can use to validate your model are:\n",
    "  - Accuracy \n",
    "  - Precision\n",
    "  - Recall\n",
    "  - F1 Score\n",
    "  - Roc Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision/Recall Tradeof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The F1 score favors classifiers that have similar precision and recall. This is not always\n",
    "what you want: in some contexts you mostly care about precision, and in other con‐ texts you really care about recall. <br><br>\n",
    "\n",
    "- For example, if you trained a classifier to detect videos that are safe for kids, you would probably prefer a classifier that rejects many good videos (low recall) but keeps only safe ones (high precision), rather than a classifier that has a much higher recall but lets a few really bad videos show up in your product (in such cases, you may even want to add a human pipeline to check the classifier’s video selection). <br><br>\n",
    "\n",
    "- On the other hand, suppose you train a classifier to detect shoplifters on surveillance images: it is probably fine if your classifier has only 30% precision as long as it has 99% recall (sure, the security guards will get a few false alerts, but almost all shoplifters will get caught). <br><br>\n",
    "\n",
    "-  Unfortunately, you can’t have it both ways: increasing precision reduces recall, and vice versa. This is called the precision/recall tradeoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Failure of Classification Accuracy for Imbalanced Class Distributions\n",
    "https://machinelearningmastery.com/failure-of-accuracy-for-imbalanced-class-distributions/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/confu2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/confu1.png)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "895aa688263384567493505d09875376e7685297a6922210da729f70c5caa3cf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('datascience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
