{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Machine Learning Case Study Projec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How to work through a regression predictive modeling problem end-to-end.  \n",
    "\n",
    "- How to use data transforms to improve model performance.  \n",
    "  \n",
    "- How to use algorithm tuning to improve model performance.  \n",
    "\n",
    "- How to use ensemble methods and tuning of ensemble methods to improve model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Definition\n",
    "\n",
    "We will investigate the Boston House Price dataset. Each record in the database describes a Boston suburb or town. The data was drawn from the Boston Standard Metropolitan Statistical Area (SMSA) in 1970. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "from numpy import arange \n",
    "from matplotlib import pyplot \n",
    "from pandas import read_csv \n",
    "from pandas import set_option \n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.linear_model import Lasso \n",
    "from sklearn.linear_model import ElasticNet \n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.svm import SVR \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from sklearn.ensemble import ExtraTreesRegressor \n",
    "from sklearn.ensemble import AdaBoostRegressor \n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV'] \n",
    "\n",
    "dataset = pd.read_csv(\"/Users/shamsuddeenmuhammad/Documents/VScode/Introduction_to_machine_learning_with_Pyhon/data/housing.csv\", delim_whitespace=True, names=names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273.0   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273.0   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273.0   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273.0   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    }
   ],
   "source": [
    "#print shape of the data \n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the data type of each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM       float64\n",
      "ZN         float64\n",
      "INDUS      float64\n",
      "CHAS         int64\n",
      "NOX        float64\n",
      "RM         float64\n",
      "AGE        float64\n",
      "DIS        float64\n",
      "RAD          int64\n",
      "TAX        float64\n",
      "PTRATIO    float64\n",
      "B          float64\n",
      "LSTAT      float64\n",
      "MEDV       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can see that all of the attributes are numeric, mostly real values (float) and some have been interpreted as integers (int)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s now take a peek at the first 20 rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
      "0   0.00632  18.0   2.31     0  0.538  6.575   65.2  4.0900    1  296.0   \n",
      "1   0.02731   0.0   7.07     0  0.469  6.421   78.9  4.9671    2  242.0   \n",
      "2   0.02729   0.0   7.07     0  0.469  7.185   61.1  4.9671    2  242.0   \n",
      "3   0.03237   0.0   2.18     0  0.458  6.998   45.8  6.0622    3  222.0   \n",
      "4   0.06905   0.0   2.18     0  0.458  7.147   54.2  6.0622    3  222.0   \n",
      "5   0.02985   0.0   2.18     0  0.458  6.430   58.7  6.0622    3  222.0   \n",
      "6   0.08829  12.5   7.87     0  0.524  6.012   66.6  5.5605    5  311.0   \n",
      "7   0.14455  12.5   7.87     0  0.524  6.172   96.1  5.9505    5  311.0   \n",
      "8   0.21124  12.5   7.87     0  0.524  5.631  100.0  6.0821    5  311.0   \n",
      "9   0.17004  12.5   7.87     0  0.524  6.004   85.9  6.5921    5  311.0   \n",
      "10  0.22489  12.5   7.87     0  0.524  6.377   94.3  6.3467    5  311.0   \n",
      "11  0.11747  12.5   7.87     0  0.524  6.009   82.9  6.2267    5  311.0   \n",
      "12  0.09378  12.5   7.87     0  0.524  5.889   39.0  5.4509    5  311.0   \n",
      "13  0.62976   0.0   8.14     0  0.538  5.949   61.8  4.7075    4  307.0   \n",
      "14  0.63796   0.0   8.14     0  0.538  6.096   84.5  4.4619    4  307.0   \n",
      "15  0.62739   0.0   8.14     0  0.538  5.834   56.5  4.4986    4  307.0   \n",
      "16  1.05393   0.0   8.14     0  0.538  5.935   29.3  4.4986    4  307.0   \n",
      "17  0.78420   0.0   8.14     0  0.538  5.990   81.7  4.2579    4  307.0   \n",
      "18  0.80271   0.0   8.14     0  0.538  5.456   36.6  3.7965    4  307.0   \n",
      "19  0.72580   0.0   8.14     0  0.538  5.727   69.5  3.7965    4  307.0   \n",
      "\n",
      "    PTRATIO       B  LSTAT  MEDV  \n",
      "0      15.3  396.90   4.98  24.0  \n",
      "1      17.8  396.90   9.14  21.6  \n",
      "2      17.8  392.83   4.03  34.7  \n",
      "3      18.7  394.63   2.94  33.4  \n",
      "4      18.7  396.90   5.33  36.2  \n",
      "5      18.7  394.12   5.21  28.7  \n",
      "6      15.2  395.60  12.43  22.9  \n",
      "7      15.2  396.90  19.15  27.1  \n",
      "8      15.2  386.63  29.93  16.5  \n",
      "9      15.2  386.71  17.10  18.9  \n",
      "10     15.2  392.52  20.45  15.0  \n",
      "11     15.2  396.90  13.27  18.9  \n",
      "12     15.2  390.50  15.71  21.7  \n",
      "13     21.0  396.90   8.26  20.4  \n",
      "14     21.0  380.02  10.26  18.2  \n",
      "15     21.0  395.62   8.47  19.9  \n",
      "16     21.0  386.85   6.58  23.1  \n",
      "17     21.0  386.75  14.67  17.5  \n",
      "18     21.0  288.99  11.69  20.2  \n",
      "19     21.0  390.95  11.28  18.2  \n"
     ]
    }
   ],
   "source": [
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s summarize the distribution of each attribut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
      "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
      "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
      "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
      "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
      "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
      "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
      "\n",
      "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
      "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
      "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
      "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
      "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
      "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
      "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
      "\n",
      "            LSTAT        MEDV  \n",
      "count  506.000000  506.000000  \n",
      "mean    12.653063   22.532806  \n",
      "std      7.141062    9.197104  \n",
      "min      1.730000    5.000000  \n",
      "25%      6.950000   17.025000  \n",
      "50%     11.360000   21.200000  \n",
      "75%     16.955000   25.000000  \n",
      "max     37.970000   50.000000  \n"
     ]
    }
   ],
   "source": [
    "# descriptions \n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The min and max values as well are the means vary a lot. We are likely going to get better results by rescaling the data in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s now take a look at the correlation between all of the numeric attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
      "CRIM     1.000000 -0.200469  0.406583 -0.055892  0.420972 -0.219247  0.352734   \n",
      "ZN      -0.200469  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \n",
      "INDUS    0.406583 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \n",
      "CHAS    -0.055892 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \n",
      "NOX      0.420972 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \n",
      "RM      -0.219247  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \n",
      "AGE      0.352734 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \n",
      "DIS     -0.379670  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \n",
      "RAD      0.625505 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \n",
      "TAX      0.582764 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \n",
      "PTRATIO  0.289946 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \n",
      "B       -0.385064  0.175520 -0.356977  0.048788 -0.380051  0.128069 -0.273534   \n",
      "LSTAT    0.455621 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \n",
      "MEDV    -0.388305  0.360445 -0.483725  0.175260 -0.427321  0.695360 -0.376955   \n",
      "\n",
      "              DIS       RAD       TAX   PTRATIO         B     LSTAT      MEDV  \n",
      "CRIM    -0.379670  0.625505  0.582764  0.289946 -0.385064  0.455621 -0.388305  \n",
      "ZN       0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.412995  0.360445  \n",
      "INDUS   -0.708027  0.595129  0.720760  0.383248 -0.356977  0.603800 -0.483725  \n",
      "CHAS    -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.053929  0.175260  \n",
      "NOX     -0.769230  0.611441  0.668023  0.188933 -0.380051  0.590879 -0.427321  \n",
      "RM       0.205246 -0.209847 -0.292048 -0.355501  0.128069 -0.613808  0.695360  \n",
      "AGE     -0.747881  0.456022  0.506456  0.261515 -0.273534  0.602339 -0.376955  \n",
      "DIS      1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.496996  0.249929  \n",
      "RAD     -0.494588  1.000000  0.910228  0.464741 -0.444413  0.488676 -0.381626  \n",
      "TAX     -0.534432  0.910228  1.000000  0.460853 -0.441808  0.543993 -0.468536  \n",
      "PTRATIO -0.232471  0.464741  0.460853  1.000000 -0.177383  0.374044 -0.507787  \n",
      "B        0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.366087  0.333461  \n",
      "LSTAT   -0.496996  0.488676  0.543993  0.374044 -0.366087  1.000000 -0.737663  \n",
      "MEDV     0.249929 -0.381626 -0.468536 -0.507787  0.333461 -0.737663  1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(dataset.corr(method='pearson'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can see that many of the attributes have a strong correlation (e.g. > 0.70 or < −0.70)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example: NOX and INDUS has correlation of  0.77."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unimodal Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histograms \n",
    "dataset.hist(sharex=False, sharey=False, xlabelsize=1, ylabelsize=1)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributions in Data science: https://www.kdnuggets.com/2020/02/probability-distributions-data-science.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s look at the data with box and whisker plots of each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# box and whisker plots \n",
    "dataset.plot(kind='box', subplots=True, layout=(4,4), sharex=False, sharey=False, fontsize=8) \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This helps point out the skew in many distributions so much so that data looks like outliers (e.g. beyond the whisker of the plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal Data Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s also visualize the correlations between the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVkAAAD+CAYAAACQnHY5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAxqElEQVR4nO2defxVVdX/3x/giyIoqCggoGiROJOh9oiZlqbyWEiDSmnSTyNL0pzK6nl6eBqeHFKzHMmcKkHNTEqch7ScRVQQZ1ERJ8RwYvx+1++PvS8eLvd+7/nec2fX+/U6r3vO3nvtvc495667zzp7ry0zw3Ecx6kO3eqtgOM4TivjRtZxHKeKuJF1HMepIm5kHcdxqogbWcdxnCriRtZxHKeamFlLbcBAYBrwLPA4MAP4GLAEmBXTLgPaYvk9gL/H/QmAAZ9N1HdyTHs+ys8COoBvx/TvAsPi/j+ACVHu7MT+JVH+EeCp2P7gRBvv5un9MjAv6v0UcEdsdy7wEHBCQrYHsBD4ZTw24HRgf+BhYAHwBvCtmD8ReCJu9wO7xfTjgN8n6u0AFgOzgb8B/WJ67lx/lijbH1gRz3lczB+RyN85nsPTwEzgOmC7mDc5nm/uuzXgMWBO/L6OA7oVuFYDgL/HMo9HuVn5+iZ0eASYmpeWuy6zgaXAIuD1hD4W8yx+74Nj+qPASuDVhN6zgfa0OgDfSMguj+c8i3C/TQDOjuXagZeifkvjddktr94tWf0emQLsk6j/XeDJeB7PRpncdVoUv8f7gBdjeysJv5clwF6Ea76EcD/NJdw3hyWuyT15+vQAXgMG1dseNMJWdwUqejIg4B7gyETaSOBTwOx43B24Dfha4iZJGtlHgQsT8lfEG/XL8XgiwZhuEW/4Z4Dh8ab6N3B4LJdvZL+c0PFYgvHsGdPeTeod9ZgW9X4HGJvQ51xWN7JjgH8RjLPiD/F5ggEYApwA/Cz+EPcnGIv+UXbH+MMaGH8Ys4DRQL94blvEcpcCP477w2JbDyd0+HaUPRu4ErgLmBzzBhD+MHZNlN8NOCDuT847n3cT+xsDtwD/W+BaXQAckyj7fmJ/lb7xeCuCEXsZ6J1IL3Rd3gR+kLgu34nn8xpwXEL2KuDJuP/DqM+7XdUh5s3LXZPE9c8Z2SW5a0YwnO25a5YofyOr3yPb5dV/BzAqns/DQK94nWYT7pPk/X9Lru2E/DDi7ycebxGv9zcIT8MvAcMS+fsCt9bbHjTK1mrugj2BFWZ2fi7BzGYRboLccTvhn3hwkTruAnaW1CapD/BRwg2FpI8BPwEOJRghA24FvkToLc4nGJCiWOBMws29X0zunq83oXf6EtAW683xel6V44GzCD+8TxJ6IX8A1iUYDIB2M3sS+AFwopktjLrMJBiDo8xsJcGgnAOcGvV5Lsrfw+rf1xJgrqRR8fggwo+2jWCkDwcOjnmTgEvN7O7Ed/BPM/trJ19TrtzrhD+1SZKUlz2I1b+XjsR+vr5fJXwnNwFfKNJW7rq8C4xIZI0HjicY4R0S6XMAk/R94EiCoU3SZR2K0JMPrtl6hHvuUuCoRJnVvgsze6yT+q4n3K+jCU8WXbYB8b44DjjazDoIfzgHJYocDEztar2tSqsZ2W0J//pFkbQ2sAtwQ5EiRvg33wcYC0yP6d2Bywm9rhcT5U8Gvhn3HwL2ldQ9ha4z+eDH3K0TvbsB90t6W9LLhF5j7lx6AZ8lPO5NJRgEgF8RjM6LwNeA7SR1A7Yp0M6DMZ1oCOcSHhFXxDa6xzam58lNAw6WNITQu1oAbA7cYGZPAYsk7RjrnlniuzhW0ixJs4C1kxnxB92N0KtNcg7we0m3S/oxwQgW0/cgwhNJ8jsqxiuJtkTo5c8kPKX0zit7LXAK8HMzW5RLrIAOSboBv5b0BHAhwbWw6ppFzgRuk3S9pGMl9eukvmnA0cDNhOv1OsF459gZOCh3PeI9Vojk/TuV+KcqaS3C09XV6U+xtWk1I9sZH4k/4jeBF83s0U7KTiPcNMl/5IOBOWY2LVnQzHK+2r6ER/vnCL2WUuT3zPLJzXd+ChgKfI/w4+oeNwiP/7eb2fuEm3pc1Oltwg/vCoKh3RW4qBM9wvNy6LmPIvRIeyW+rw0IP8okNwB7EwzGFTHtY4Tvjvi5hjGRdJ+kuZLOSiSfaWYjzWwkwd1RSMfVMLMbCY+tvyP82NeR9Fi+vpJ2At4wsxcITx07Slq/yHeRTy/CE8GDcRuWlz+CYJS3zZUv9J1l1AHgU2Y2gvAYvhaJawZgZhcT3BFXEVwq90Zjtwbxvv8Y4clrBsF1luxx3w9ckbseZrakiE6rromZPQD0kbQl4ensXjN7qwvn19K0mpGdA3yiSN6z8Uf8UeCTkoo+spnZ/YQfTv/YKxtIeBSfVETkXGAjwvf5d8Jjeanv9uOEXiOEx+9RibwNCO6CnD4LzOwiMxtL6KEOjFnjgb0kzSP0UDfkAwP8a4IRnkl4TP0S4QVR/vezY0wH+F/gj8AvQrM2EtiM8MiafDzFzJbHNo8nGPjeBB/whVGfEwm9tzmxjZzcLsB/E/6USiJpC0JPOd9NgpktMrPLzezQWGZyAX3HAyOiTs8Sem1f6qTJQQT/KwRD1k7wUe8KbC9peMxbl+Aa2hkYI2l7YEmR76yrOiTpIF4zM7uHYNx244NrlvsukvfISj4w/KshaUPCtToOOIzQedikgDumFMn7Fwp3TBxaz8jeBqwlKff4nutFbJY7NrNXgJNY04eWzw+BH8Uex2jgt2b2TpGyzwLLCEbtFcIPYP9CBRU4mvBjzrksbgEGS/pmfDw7MNazGaGH0BZlBxJ6V29LWo/wY9vUzIaZ2TDCj7pH7JFuT/CTHk4wyi8QfK2nxB8akkYSXnacK2k74D8Jj79Toqp7m9liwuPlCTk9EpxOeEn0JrAT8ISZbRb1GUp4AXcTMEHSrgm5dYp8j/nf1UbA+YQXMZaX9xlJ68T9dQn38ot5+q4FfAXYPvEdjaVwDzt3XfoAT8ZemcxscEL2l3zga96H8HJnPsFgnZOrq1wdirCceM0kjSAY2QMJf+w53ffNu0c2JLxgK8SXCU8ex5nZ4FjX+5R4l5BE0jCCS+q3ieSpwCHAZ1jTtfShpke9FagkZmaSxhF8WCcRHj3nER61k/wVmCzpU53UdT2ApB8S/ITflHRgokj+v/UbhMdXCD3Bh/PyT5P03wQDcy+wZ+wNAhxDeNN9KuEN/VuEH+L3CD/62ZJyj9E3E9wSXwRuM7NliTauJbgFugPfJzwWDiE8Qn7RzB6UNBi4W5LFeg4hvIS7CjjWzJbG814GnCVppJk9LOkRgoG5K/EdzSH0VCH09J/KO+erCa6TgwiGYjChR7oQ+Gmi3LGSDon7vSXlhmTlXuKdwZp8Ajhb0kqCgV0RH1tJ6Hsg8LKZJQ3OncDWkgbF4/zrcimh9zo+tp9/PtMk3Uvoid8f2/tb/GNf9XtKq0P80++MnoQ/yaT82sADsfN5BuEan5W4R040s1eL1DceONnMku8kXiFcp/sIPfMdJOWM7ncI/vaPSHo4tv0OodNxceJ8H5f0PvCQmb1X4pw+VCivg+A4juNUkFZzFziO4zQUbmQdx3GqiBtZx3GcKuJG1nEcp4p8qI2spIn1kve2P1xtZ5Vv5rZrjaSLJL0uaXaRfEn6jaRnJD2qMDMxl7evpCdj3kkVUaicgAetsgEP1kve2/5wtd3Mumdtu9YbsDthAszsIvljCDEcRBh6eF9M704Y874FYejcI8DWWfX5UPdkHcdpPczsTkIIx2KMBS6zwL1AvzhuemfgGTN7zsIY9mmxbCZaajJCPv036G7DhuZPUvqATQf3YNQOaxcdKDzn9Y06rb/HeuvTa9DQgvJt6y0vlLyKtQesy3pbDija9vL3enbedr/1WXtI4bbX6l267b6dtb2487bb1lufXgMLt919vRWdyvbceD36fGxg0bZtUfHrBdCz9/r07l+4bYB+A4pNyoO+g3oxeJt+RWXbS/Q51h20DgO32aCo/NvL1y6WBUDbRuuxzvBNCsrrrc5jCpU67579lxXLAqDXgD6sP2LjgvLLFxYMc5C67fffnL/QzDr/sZRgnz1725uL2lOVfejRZXNYPcbFFDOb0oXmBpOIzEeIYDa4SPouXai3IC1tZIcNbeP+G4eWLb/tWd8pW3bIPi+ULQvw3P2bli370V2ytf3SdcPKlu27V7GJRulYPm1AJvkDjrutbNnF7cUCTqXjphdHlC5UhLa/dCVezJpsesTTZcu+eOHw0oU64aFLjs92wwELF7Vz341DUpVtG/TsUjMbVbpkUQrFabBO0jPR0kbWcZxmwWi3jtLFKsN8QmS7HEMIU4d7FknPhPtkHcepOwZ0YKm2CjAd+HocZfBJYLGFGBIPAMMlbS6pJyFWR+ZgN96TdRynIeigMj1ZSVMJQZH6S5oP/A8hRjIWVh+ZQRhh8AwhAtk3Yt5KSZMIy/l0By6yEAQpEzUxsjH82q8J4fCW8UFkrEcIC7z1JARFPtzMVkjag7ACwf6SJgAXA3uZ2a2xvnHAX4CvmNmfa3EOjuNUD8NYUSF3gZl1GkbSwnito4rkzSAY4YpRdXdBDAZ8DXCHmX3EzLYGfkRYYC8XSHs7gv/jwCLVPMbq8TcPJhhox3FagBAd3VJtzUYterIFFzeMgX9zx+2SSi1u+KkYmHgtEosbOo7TGlTI39pw1MLIdmVxw2OKFEkubtiX4IzevEhdEwkrnLLpYHc5O04zYEC7taaRrffogqyLG66BmU0xs1FmNmqjDdMsGus4TiPQkXJrNmphZKu1uKHjOC2CpfTHNqNPthZGtuKLG1ZDScdx6ocZrEi5NRtVN7JxuMQ4YG9Jz0qaQ1i6OX8mxV+BdUotbmhmt1dLV8dx6oVoT7k1GzV5M2RmCyg8PGvbRBkDdkjk3RHTLyGs5Jpf54QKqug4Th0xoKMJe6lp8NfvjuM0BM3YS02DG1nHcepOmIzgRrbpmPP6RpnCFc4+5tyyZff45jdLF+oE27182ffOSBcyrhg9Jy4sW7btzA0ytX3QGdlmNF589pjyhTM+rvZ8v3zZhZ9bWrpQJ3S74KNly659aLbwlGs687qOASus3iNKq0NLG1nHcZoDQyWDpjcrbmQdx2kIOszdBY7jOFWhlX2yDdU/lzRO0qy8rUPStyWZpO8myp4dwyA6jtP0iHbrlmprNhpKYzO7xsxG5jbgXEIErhuB14FjYsRyx3FaiLAyQrdUW7PRsO4CSR8DfgLsSvgzeAP4F3AY8Ls6quY4ToUxE8utNQM6NeTfQowbezlhdYQXE1knA8dLas2r4TgfYjpQqq3ZaEgjC/wMmGNm05KJZvY8cD/w1WKCkiZKelDSgyvff6/KajqOUwnCi69uqbZSSNpX0pOSnpF0UoH8ExPvfGZLape0QcybJ+mxmPdgJc6t4dwFcX2vLwE7Finyf8CfgTsLZZrZFGAKQK9BQ1t0NrTjtBqqyEut+JR7DrA3YenvByRNN7PHc2XM7DTgtFj+88CxZrYoUc2eZlb+jJw8GqonK2l9wqKJXzezdwqVMbMngMeB/Wupm+M41aOCL752Bp4xs+fMbDkh2P/YTsqPp5NFACpBo/VkjwQ2Bs4L6y+uIv9L+AXwcK2Uchyn+rRXZjLCYOClxPF8wtJWayBpHWBfYFIi2YCbJBlwQXwyzkRDGVkz+yXwyyLZpyTKPUKD9cIdxykfQ6yw1Oaof56/dErCGBay1MXchp8H/pXnKhhtZgskbQzcLOkJMyvomkxLQxlZx3E+nORefKVkoZmNKpI3HxiaOB7CmgsE5FhjvcAY+xoze13SNQT3QyYj671Bx3HqjiHaLd1WggeA4ZI2jxOXDiasbr0akvoCnwauTaT1lrRubh/4HDA767m1dE+2bb3lDNnnhbLls4QrvON32eZLbH7txLJljz/jj5na/sXPDitbdszpN2Vq+7pDdsskP+bif5Ytu1WvYh2edFz00uiyZdunDs7U9j4nlt/ZuvWn2b7zSlGJ2VxmtlLSJMIs0e7ARWY2R9KRMf/8WHQccJOZJcd5DgCuie+DegCXm9kNWXVqaSPrOE5zYEbF4hKY2QxgRl7a+XnHl5AXCdfMnmP1JbAqghtZx3HqTnjx1ZoTOd3IOo7TEHjQbsdxnCphqGWDdlfsr0PSu/FzWGexXyVdIul5SY9IekrSZZIG59eTOJ4g6ey4v6WkO+K84rmSMg8UdhynMahU7IJGo1oal4r9eqKZ7QBsSZi5dXvKOLG/Ac6M8Wa3An5bGXUdx6knBnRYt1Rbs1Etjd8AbiXEfi2KBc4EXgX2S1HvIMJg45z8Y1mUdBynURDtKbdmo5p/C12J/ToTGJGi3JnAbZKul3SspH75BZKhDlcsXtI1jR3HqQthSfDuqbZmo2pGNk3s1wSl/p4s1nkxsBVwFbAHcK+ktfLanWJmo8xsVFvfXl3W23Gc2mMmdxeUyf8BP0jRzseBuXF/SZ5/dgNgVWxHM1tgZheZ2VhgJbBtBfV1HKdO+EKKZVAq9qsCRxN8rbnpa/8ADon5vYADgdvj8b5xaRokDQQ2BF6u5jk4jlN9QjxZX36mXH5BiIST5DRJjwBPATsRIpEvj3nHAF+UNAu4F7gqEWrsc8DsKHsjYZTCq9U+Acdxqk3rLglesckIZtYnfs4j8QifH/vVzCaUqOdlivR8zew44Ljs2jqO00iEIVzN10tNg8/4chyn7njsAsdxnCpTiVCHjUhLG9nl7/Xkufs3LVvedi+/7SzxYAGeH1v+jOHN/1Z+HFwARq8sW/Tcf30mU9M9v5jtlnz6tvJjunZbme1xtcf75csv27E9U9uXX1/+zdoxbmmmtvlzNnHIhTp0d4HjOE7VcJ+s4zhOlQhRuNxd4DiOUxXCtFo3so7jOFWidXuyVTsrSQMlTZP0rKTHJc2Q9DFJs/PKTZZ0QuK4h6SFkn6ZV25/SQ/HOLSPS/pWtXR3HKf2VGrGV5wZ+qSkZySdVCB/D0mLY1zqWZJ+kla2HKrSk1VY7vEa4FIzOzimjSSsBlmKzwFPAgdK+pGZWZxKOwXY2czmx6Aww6qhu+M4tadSowti1L9zgL0JYVEfkDTdzB7PK3qXme1fpmyXqFZPdk9gRXKFSDObBbyUQnY8cBbwIvDJmLYu4Q/hzVjXMjN7spIKO45TXyoUhWtn4Bkzey5O1Z8GjE2pQhbZolTLyG4LPFQk7yOJbvos4MhcRgwI81ng78BUgsHFzBYB04EXJE2V9DVJBXVPxpNtf++9QkUcx2kwcmt8pdmA/rnfeNySg9IHs3pnbn5My+c/ouvxeknbdFG2S9TjxdezZjYydyBpciJvf+B2M3tf0tXAf0s61szazewISdsBewEnELr0E/IrN7MpBNcCaw8ZalU7C8dxKoYBK9O/+FpoZqOK5BXyOeTbgZnAZmb2rqQxwF+B4Sllu0y1erJzgE+UITce2EvSPEJPeEOC6wEIy83E5Wr2Br5UAT0dx2kQKuQumA8MTRwPARYkC5jZ22b2btyfAbRJ6p9GthyqZWRvA9aStGp+p6SdgM2KCUhaD9gN2NTMhpnZMOAoYLykPpL2SBQfCbxQebUdx6kLKV0FKWaFPQAMl7R5DP5/MMHVuIo48klxf2eCHXwzjWw5VMVdEEcEjAN+HYdBLAXmAd/rROyLwG1mtiyRdi1wKiG84fclXQAsAd6jgKvAcZzmJBe0O3M9ZislTSLEm+4OXGRmcyQdGfPPB74MfFvSSoI9OdjMDCgom1WnqvlkzWwBYVWDfLbNKzc5cXhJXt4iYKN4OKaC6jmO02BUKnZBdAHMyEtLjnQ6Gzg7rWxWfMaX4zh1x4N2Nylr9V7OR3cp33X73hn5q+ak5/gz/li2LGQLV/j853+Xqe2P//w7Zcv+4Jipmdq+7AufzSS/y5XljxvfoEe2IX9nPbJn6UJF6H9TtpWV9zrmX2XL3n7arpnanpdJOmCIlR2tOa22pY2s4zjNQzMukpgGN7KO49Qfc3eB4zhO1XCfrOM4TpVpVSNbc0+zJJN0euL4hOTU2hh74Im43S9pt5h+nKTfJ8p9TdJ1NVXecZyqYIj2jm6ptmajHhovA74Yp7GthqT9gW8Bu5nZCELwmMslDQR+A3xC0mhJ/YCfA9+tndqO41STSsWTbTTqYWRXEgK4HFsg7wfAiWa2EMDMZgKXAkeZ2UrgO4R4j6cSZmM8VxuVHcepJhZffFVgWm3DUa++9znA1yT1zUvfhjVDJD4Y0zGzu4G5hEhcpxaqOBnqcPniJZXV2nGcqmGmVFuzURcja2ZvA5cBR6coLmK4MUl9gFFAGx9Mt82ve4qZjTKzUT37Zhvg7ThOrahYgJiGo55e5F8DhwO9E2mPs2aIxB1jOsD/An8EfgGcWWX9HMepId6TrTAx+MuVBEOb41TgFEkbwqp1wSYA58aA3f8JnELw6W4mae9a6uw4TnUwg/YOpdqajXqPkz0dmJQ7MLPpkgYDd0sy4B3gEOBV4CrgWDNbCiDpO8BlkkbG9Xgcx2limnHkQBpqbmTNrE9i/zVgnbz884DzCojullfuQWDraujoOE5tMWhKV0Aa6t2TdRzHIffiqxVxI+s4TkNgLbrsaUsb2eWLe/LSdcPKlu85cWHZsr/42WFlywIwemXZolniwQI8/F/nli27/a+ytb10craYri/9aY+yZTOGk6Xf0vKtxBu7r8jU9v3HFlu8tTRHnPfXbG3/KZP4KlrVXdB8E4Edx2k5wuiCysQukLSvpCclPRPXGMzP/5qkR+N2t6QdEnnzJD0maZakBytxbi3dk3Ucp3mohLtAUnfCjNK9CUt8PyBpupkll8x4Hvi0mb0laT/CkNBdEvl75qb2VwI3so7jNAQVchfsDDyTi2siaRowlg8mNOWm5+e4Fyh/nakUuLvAcZy6Y6Sb7RUNcf9cfJK4TUxUNRh4KXE8P6YV43Dg+tVUgZskPZRXb9k0TE9WUjvwGEGn54FDzezfkobF45+b2X/Hsv2BV4ALzGxSkSodx2kiuuAtWGhmxd70FeoOF6xa0p4EI5scgz/azBZI2hi4WdITZnZnetXWpJF6skvMbKSZbQssAo5K5D0H7J84/gowp5bKOY5TRQysQ6m2EswHhiaOhwAL8gtJ2h64EBhrZm+uUsNsQfx8HbiG4H7IRCMZ2ST3sHoXfwkwV1Lu3+sgQtwDx3FahAoFiHkAGC5pc0k9gYOB6ckCkjYF/kJ4Wn4qkd5b0rq5feBzwOys59Uw7oIc8e3gZ4Hf52VNAw6W9CrQTvh32qSA/ERgIkDbeutXV1nHcSpGJUYXmNlKSZOAG4HuhOD+cyQdGfPPB34CbEgIPAWwMrofBgDXxLQewOVmdkNWnRrJyPaSNAsYRgjcfXNe/g3Az4DXgCuKVWJmUwhDMug1cGiLziFxnNaikrELzGwGMCMv7fzE/hHAEQXkngN2yE/PSiO5C5aY2UhgM6Anq/tkiZG2HgKOB66uuXaO41QPA0zptiajkXqyAJjZYklHA9dKyo/GdTrwDzN7M3bpHcdpETx2QQ0xs4clPUJwWt+VSJ+DjypwnBYk1ciBpqRhjGwyzmw8/nzicNsC5S8BLqmuVo7j1AzvyTqO41QJa90oXC1tZLuvt4K+e71atnzbmRuULTvm9JvKlgU491+fKVv2B8dMzdR2lnCFj55QfphEgDF7H5RJfp3zXy5bdt22ZZnafmDBpmXL9r29b6a2R5/1j7JlLzhlXKa24Z8Z5SPek3Ucx6km3pN1HMepHh31VqA6uJF1HKf+5MbJtiBuZB3HaQhadZxs3WZ8SRonySSNSKTtLOkOSU9LminpOknbxbzJkl6Oy0Lktn710t9xnApjKbcmo5492fGE15IHA5MlDSBE1vpqLnK5pN2AjxDizAKcaWa/qoeyjuNUGXcXVA5JfYDRwJ6EMGSTgUnApcmlIcysQmNDHMdpdNSEvdQ01MtdcABwQ4zluEjSjsA2wMwScscmXAW3FyogaWJuWYoVi5dUVmvHcaqDCTpSbk1GvYzseEJ8WOLn+PwCku6TNFfSWYnkM+PqCSPNbM9CFZvZFDMbZWaj2vr2qrzmjuNUB/fJVgZJGwKfAbaVZITAugZcCuwIXAtgZrtI+jKrLzvjOE6r0oQGNA316Ml+GbjMzDYzs2FmNpSwUOJNwARJuybKrlMH/RzHqQfek60Y44GT89KuBr5KWLvrFEmDgdeBhcBPE+WOlXRI4vgAM5tXRV0dx6kFPhmhcpjZHgXSfpM4/HQRucmEUQiO47QglRpdIGlf4CyCK/JCMzs5L18xfwzwPjDBzGamkS2HRlp+xnGcDzMVcBfEhVjPAfYDtgbGS9o6r9h+wPC4TQTO64Jsl3Ej6zhOQyBLt5VgZ+AZM3surgs4DRibV2Ys4b2Qmdm9QD9Jg1LKdpmWjl1gi9pYPm1A2fIHnTGjdKEiXHfIbmXLAvT8YvmX5rIvfDZT20snv1e2bNZ4sDNuLroQcSo+ddS3ypZduDxbGKhuI9rKltVeizK1fdvk8u+3d7/2Tqa2uTib+CrS+2T7S3owcTwlrlINMBh4KZE3H9glT75QmcEpZbtMSxtZx3GahK6NHFhoZqOK5BWy1Pk1FyuTRrbLuJF1HKcxqMyLr/nA0MTxEGBByjI9U8h2GffJOo7TEKgj3VaCB4DhkjaX1JMQgGp6XpnpwNcV+CSw2MxeSSnbZbwn6zhOY1CBnqyZrZQ0CbiRMAzrIjObI+nImH8+MIMwfOsZwhCub3Qmm1WnhjCyktoJ4QzbgJWEKba/NrMOSXsAJ5jZ/jEc4u8JXfo2YJ6ZjamP1o7jVIqUIwdSYWYzCIY0mXZ+Yt+Ao9LKZqUhjCywxMxGAkjaGLgc6Av8T165nwI3m9lZsez2tVTScZwq0qIzvhrOJ2tmrxMGCE+KMzOSDCI4rXNlH62lbo7jVJEWjV3QcEYWwMyeI+i2cV7WOcDvJd0u6ceSNsmXTcaTXbm0/PGejuPUlgpNRmg4GtLIRtZ4djCzG4EtgN8BI4CHJW2UV2ZVPNkea/eujaaO42TDKja6oOFoSCMraQugnRCJazXMbJGZXW5mhxKGXOxea/0cx6kC7i6oDbFnej5wdnwLmMz7jKR14v66hEUWX6y9lo7jVJwWNbKNMrqgl6RZfDCE6w/AGQXKfQI4W9JKwh/EhWb2QM20dBynajSjvzUNDWFkzax7J3l3AHfE/dOA02qjleM4TnYawsg6juM0oysgDW5kHcepP9acIwfS0NJGtt+AdzjguNvKlr/47PJn7I65+J9lywI8fdvosmV3ufLxTG2/9Kc9ypZd5/yXM7WdJR4swF3nXFC27PyV72Zq+7gXy4/vPP/s4Zna3uzEJ8qWXTZlq0xtVwzvyTqO41QH4S++HMdxqosbWcdxnCrRpFNm01DzyQiS2iXNkjRb0t8k9cvLf0TS1Ly0SyQ9H/OeknSZpME1VdxxnOrSkXJrMuox42uJmY00s22BRSTiOkraKuq0u6T8wAMnmtkOwJbAw8DtMXq54zgtgAeIqQ73EFaIzPFVwmyvm4AvFBKIy/ieCbxKWB/dcZxWoEWn1dbNyErqDnyW1dfQOQi4ApgKjC9RxUxCJK78eleFOnzvreWVUtdxnGqS1sC6kU1FLk7Bm8AGwM0AknYC3jCzF4BbgR0lrd9JPQXDqCdDHfZe370JjtMs1MJdIGkDSTdLejp+rmFjJA2NMavnSpoj6ZhE3mRJL8f3SrMklRxMXzefLLAZYQnenE92PDBC0jzgWWA94Eud1PNxYG711HQcp6bUpid7EnCrmQ0ndOZOKlBmJXC8mW0FfBI4StLWifwz43ulkXFNsE6pm7vAzBYDRwMnSFoL+AqwvZkNM7NhwFgKuAziMr5HE5aiuaGGKjuOU0VqFLR7LGGhVuLnAfkFzOwVM5sZ998hdObKHs1U1xdfZvYw8AhwIPCymSXnZN4JbC1pUDw+TdIjwFPATsCeZuZOV8dpBbrmk+2fe+8St4ldaGmAmb0CwZiy5hJXqyFpGOGp+b5E8iRJj0q6qIRLE6jDZAQz65N3/Pm4+4e89HZCbxVgQvU1cxynXogiL1kKs9DMRhWtS7oFGFgg68dd0knqA1wNfM/M3o7J5wE/I5j7nwGnA/+vs3p8xpfjOI1BhUYOmNlexfIkvSZpkJm9Ep+S11jiKpZrIxjYP5nZXxJ1v5Yo8zvg76X0qfc4WcdxHKBmkxGmA4fF/cOAa9fQQxLwe2CumZ2RlzcocTgOmF2qwZbuybbTjcXtvcqvIMMF3arXgvKFgW4ru/DwlMcGPbIthZ5FfN22ZZnaXrg825uNLOEKh/ToU7pQJ3RY+dcsK/3alpQt2/Zeg8xVrc0Y2JOBKyUdTlgf8CsAkjYhLGc1BhgNHAo8FoebAvwojiQ4VdLIqO08oGRszpY2so7jNAk1CtptZm8SJkHlpy8AxsT9f1J8HP6hXW3TjazjOI1BE87mSoMbWcdxGoJmDP6SBjeyjuM0Bi1qZOsyukDShom5v6/mzQUeIGmFpG8lyq8r6VlJw+Nxm6THJO1SD/0dx6k8HuqwgpjZm7m5v8D5JOYCE+IV3EtiSm2c2vZD4JyYdAJwt5ndh+M4zY/hQbtryHjgeGBIcvUDM7sS6JD0feBIgtF1HKcFyC2k6D3ZKiNpKDDQzO4HriTEl03yPeAU4OdmtqhIHaviyb7/VrYxm47j1BCPJ1sTDiYYV4BprBmFa1/gFWDbYhUk48mus/5a1dHScZyKI7NUW7PRaEZ2PDAhxpSdDuyQeNm1CSE04s7AGEnb101Lx3Eqi6+MUH0kbQn0NrPBiZiyvyT0bgHOBP7PzOYDxwHnxDnGjuO0AO6TrT7jgWvy0q4GxkvaG9iUELQBM/sb8Bbw9Zpq6DhO1ahR0O6aU/fJCGY2uZO8R4Hcsg835+UVXM3WcZwmpQl7qWmou5F1HMehSV0BaXAj6zhOY+BGtvl4e/na3PTiiLLle75fftsXvTS6fGGgx/vlv9M765E9M7Xdb2n5d/sDCzbN1Ha3EW2Z5I97cWzZslnjwf75I7eULbvN5h/L1PbstwaVLlSE7ivqb91ykxFakZY2so7jNA/qaE0r60bWcZz606RjYNPgRtZxnIagGYdnpaGkkZXUDjwWy84lxA+4LmYPBNqBN+LxzsCSRPnngUPN7N+J+h4BHjez8ZK+ARwTs7YGnoz13QA8AYwys0lRbiJhEgLA28BxcZkIx3FagRr0ZCVtAFwBDCOs0XWgmb1VoNw84B2CPVqZW4I8rXySNJMRlsQwhNsCy4GDioUpNLPleeUXAUclFN8qtrm7pN5mdnGirgXAnvH4pLwT3p+wYNluZjaCEIXrckmF1lZ3HKcJqdGMr5OAW81sOHBrPC5Gzh6NKlMe6PqMr7uAj3ah/D3A4MTxV4E/ADcBXZlM8APgRDNbCGBmM4FLSRhwx3GaGAPM0m3ZGEuwHcTPA6otn9rISuoB7EdwBaQp352wKuT0RPJBhK72VNaMsNUZ2wAP5aU9GNPz210V6nDl4mxLYzuOUzu6MK22f+43HreJXWhmgJm9AhA/Ny5SzoCbJD2UV39a+VWkefHVK7H2+F3E+AEpyg8jGMabASTtBLxhZi9Img9cJGn9Uv6MThAFvDhmNgWYArDO8E1a9H2l47QWXRwnuzDvEX71uqRbCO+L8vlxF1QabWYLJG0M3CzpCTO7swvyq0hjZJdEn2lalpjZSEl9gb8THul/Q+i5jogOZYD1CEvNXJiizseBTwC3JdJ2jOmO4zQ7lXEFxKpsr2J5kl6TNMjMXpE0CHi9SB0L4ufrkq4hvNS/E0gln6RqUbjMbDEh/usJktYCvgJsnwhjOJb0LoNTgVMkbQggaSQwATi3wmo7jlMnavTiazpwWNw/DLh2DT2k3pLWze0DnwNmp5XPp6rjZM3s4Thk60DgZTN7OZF9J7B17l+hRD3T43pfd0sywtCKQ0rJOY7TRNTGuXcycKWkw4EXCZ2/3KIAF5rZGGAAcE0MV90DuNzMbuhMvjNKGlkz69NJ3uRS5c3s83H3D3np7cCgxPGwvPxLgEsSx+cB55XS13Gc5qQWsQvM7E3CC/n89AXAmLj/HLBDV+Q7w2d8OY5Tfwxob8331G5kHcdpCDwKVxOit7rT9pf1y5Zf+LmlZcu2Tx1culAnLNuxvWzZ/jf1ytT2G7uvKFu27+19M7WtvQqu9J6a+WcPzySfhSzhCud8N9s73J3+69tly3af+EbpQp2Rv2hUuTThSrRpaGkj6zhO8+A9WcdxnGrhoQ4dx3GqhwD5iy/HcZzqIffJ1p9EbFsR4jxOMrO766uV4ziZcXdBw7AqjoKkfYBfAp+uq0aO41SAysUuaDSazcgmWQ8oN4KX4zgNho8uaAxyYRTXJkzJ/Ux+gRj7cSJAz97lj5F1HKfGeE+2IUi6C/4DuEzStmYfXJ1kPNne/Ye25lVznFbDWnd0QdVCHVYbM7sH6A9sVG9dHMepAJZyazKarSe7CkkjgO7Am/XWxXGc7PgQrsYguRSOgMNiyETHcZodN7L1x8y611sHx3GqgAEd9VaiOjSVkXUcpzUR5u4Cx3GcqtLRml3ZljayPfsvY9Mjni5bvtsFHy1bdp8Ty1o9eBWXX7972bJ7HfOvTG3ff2zR1ZZLMvqsf2Rq+7bJu2WS3+zEJ8qW7de2JFPbs98aVLpQEbLEgwV44Oflr8y03+cOztR2RaiRu0DSBsAVwDBgHnCgmb2VV2bLWCbHFsBPzOzXkiYD3wRyQXh/ZGYzOmuzaYdwOY7TWsgs1ZaRk4BbzWw4cGs8Xg0ze9LMRsYx+Z8A3mf10ORn5vJLGVhwI+s4TqNglm7Lxljg0rh/KXBAifKfBZ41sxfKbdCNrOM4DUBKA5vdyA4ws1cA4ufGJcofDEzNS5sk6VFJF0kqOXe/4kZW0rsF0raUdIekWZLmSpoiaZ94PEvSu5KejPuXRZlxkixOOkDSfTH/RUlvJGSHVfocHMepMbnVatNs0F/Sg4ltYrIqSbdIml1gG9sVlST1BL4AXJVIPg/4CDASeAU4vVQ9tXrx9RuCH+NaAEnbmdljwI3x+A7gBDN7MCEzHvgn4Z9kspntEstOAEaZ2aQa6e44Tg3ogr91oZkVfTtrZnsVbUN6TdIgM3tF0iDg9U7a2Q+YaWavJepetS/pd8DfSylbK3fBIGB+7iAa2KJI6gOMBg4nGFnHcVqd2rgLpgOHxf3DgGs7KTuePFdBNMw5xgGzSzVYKyN7JnCbpOslHSupX4nyBwA3mNlTwCJJO1ZbQcdx6ogBHZZuy8bJwN6Sngb2jsdI2kTSqpECktaJ+X/Jkz9V0mOSHgX2BI4t1WBN3AVmdrGkG4F9CW/3viVpBzNbVkRkPPDruD8tHs9M01YynmyvAX2yqO04Ts2ozcoIZvYmYcRAfvoCYEzi+H1gwwLlDu1qmzWbjBBP4iLgIkmzgW2Bh/LLSdqQEIx7W0lGiLRlkr6fjBvbSTur4smuP2Lj1pyn5zitSItOq62Ju0DSvpLa4v5Awj/Ey0WKfxm4zMw2M7NhZjYUeB7INhXIcZzGxYD2jnRbk1GNnuw6kuYnjs8AhgBnSVoa0040s1eLyI8n+kkSXA18Fbiropo6jtMgGFjzGdA0VNzImlmx3vFxncjsUWg/kfabxP4lwCXl6uc4ToPSou6Clg4Q4zhOk5AbXdCCuJF1HKcx8J5s87F84Vq8eOHwsuXXPrSY27g0t/4023u6jnFLSxcqwu2n7Zqp7SPO+2vZshecMi5T2+9+7Z1M8sumbFW2bNt72XyC3VeUbyS6T3yjdKFOyBKu8PqbpmVqu3v5ER5Xx42s4zhOlTCD9tZcrs+NrOM4jYH3ZB3HcaqIG1nHcZxqUZG4BA1JNeLJmqQ/JI57xPivf4/HE/Liwc6StLWkYZKWSHo4xpy9X9JhUWYPSffktdMjF7as0ufgOE6NMTDrSLU1G9Xoyb5HiDvQy8yWECLZ5E+hvSI/HmwMvv2smX08Hm8B/EVSN8IyEUMkDTOzeVFkL2B2Lsq54zhNThNOmU1DtWIXXA/8Z9xfIyZjGszsOcIssaMt/H1dBRyUKFJoWQjHcZoRs7AkeJqtyaiWkZ0GHCxpbWB74L68/IPy3AW9itQzExgR96cSA3hLWosQluzqfAFJE3PLUqxc+l4lzsVxnFpQm6DdNacqL77M7NH4+D8eKLRkbiF3QaGqViWa2QOS+sQ10bcC7s1fLz2WWxXqsHf/oc13RRznQ4o1YS81DdUcXTAd+BWwBwWC36bk48DcxPE0Qm92K9xV4DgtRHP2UtNQTSN7EbDYzB6TtEdXhWNP+FfAbxPJUwlr8vQlrP/lOE4r4AFiuo6ZzQfOKpJ9kKTk5P7vAAuAj0h6GFgbeAf4rZldnKjzcUnvAw+ZmTtcHadFMMB8Wm06zGyNhbXM7A7gjrh/CcXjwRZ7AZasa4eylXMcpzGx2gTtlvQVYDLB5bizmT1YpNy+hE5id+BCM8stuLgBcAUwDJgHHFjo3VCSWq1W6ziO0ynWYam2jMwGvgjcWayApO7AOcB+wNbAeElbx+yTgFvNbDhwazzuFDeyjuM0BtaRbsvShNlcM3uyRLGdgWfM7DkzW0544T425o0lTI4ifh5Qqk2lWAC2aZH0BvBCJ0X6AwszNJFF3tv+cLWdVb6R297MzDYqs24AJN0Q20nD2kAy4PKUOHSzK+3dAZxQyF0g6cvAvmZ2RDw+FNjFzCZJ+reZ9UuUfcvM1u+srZYOEFPqwkt60MxGlVt/Fnlv+8PVdlb5Zm47DWa2b6XqknQLMLBA1o/N7No0VRRIK7s32tJG1nGcDx9mtlfGKuYDQxPHQwijnwBekzTIzF6JwaleL1WZ+2Qdx3FW5wFguKTNJfUkTICaHvOmA4fF/cMI4/Y75cNuZLvkx6mwvLf94Wo7q3wzt90wSBonaT7wH8B1km6M6ZtImgFgZiuBScCNhBmnV5rZnFjFycDekp4mRBg8uWSbrfziy3Ecp9582HuyjuM4VcWNrOM4ThVxI+s4jlNF3Mg6juNUETeyjuM4VcSNrOM4ThVxI+s4jlNF/j8G7zku6XMEYwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# correlation matrix \n",
    "fig = pyplot.figure() \n",
    "ax = fig.add_subplot(111) \n",
    "cax = ax.matshow(dataset.corr(), vmin=-1, vmax=1, interpolation='none') \n",
    "fig.colorbar(cax) \n",
    "ticks = numpy.arange(0,14,1) \n",
    "ax.set_xticks(ticks) \n",
    "ax.set_yticks(ticks) \n",
    "ax.set_xticklabels(names) \n",
    "ax.set_yticklabels(names) \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The X  color shows positive correlation whereas the dark blue color shows negative correlation. We can also see some dark red and Y that suggest candidates for removal to better improve accuracy of models later on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far it would be worth trying:  \n",
    "\n",
    "1. Feature selection and removing the most correlated attributes. \n",
    "\n",
    "2.  Normalizing the dataset to reduce the effect of differing scales.  \n",
    "\n",
    "3.  Standardizing the dataset to reduce the effects of differing distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-out validation  dataset \n",
    "\n",
    "array = dataset.values \n",
    "\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13] \n",
    "validation_size = 0.20 \n",
    "seed = 7 \n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Algorithms: Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s create a baseline of performance on this problem and spot-check a number of different algorithms. We will select a suite of different algorithms capable of working on this regression problem. The six algorithms selected include"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear Algorithms: Linear Regression (LR), Lasso Regression (LASSO) and ElasticNet (EN).  \n",
    "\n",
    "- Nonlinear Algorithms: Classification and Regression Trees (CART), Support Vector Regression (SVR) and k-Nearest Neighbors (KNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 10-fold cross validation.  We will evaluate algorithms using the Mean Squared Error (MSE) metric. MSE will give a gross idea of how wrong all predictions are (0 is perfect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test options and evaluation  metric \n",
    "num_folds = 10 \n",
    "seed = 7 \n",
    "scoring = 'neg_mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot-Check Algorithms \n",
    "models = [] \n",
    "models.append(('LR', LinearRegression())) \n",
    "models.append(('LASSO', Lasso())) \n",
    "models.append(('EN', ElasticNet())) \n",
    "models.append(('KNN', KNeighborsRegressor())) \n",
    "models.append(('CART', DecisionTreeRegressor())) \n",
    "models.append(('SVR', SVR()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithms all use default tuning parameters. Let’s compare the algorithms. We will display the mean and standard deviation of MSE for each algorithm as we calculate it and collect the results for use later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> MSE (mean squared error) is a measure (loss function) for Regression model. A loss function in Machine Learning is a measure of how accurately your ML model is able to predict the expected outcome i.e the ground truth. Read more about three most use loss function (MSE, MAE, Huber loss) [here](https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for-machine-learning-regression-23e0ef3e14d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: -22.006009 (12.188886)\n",
      "LASSO: -27.105803 (13.165915)\n",
      "EN: -27.923014 (13.156405)\n",
      "KNN: -39.808936 (16.507968)\n",
      "CART: -26.169066 (17.077921)\n",
      "SVR: -67.824705 (32.801530)\n"
     ]
    }
   ],
   "source": [
    "# evaluate each model in turn \n",
    "\n",
    "results = [] \n",
    "\n",
    "names = [] \n",
    "\n",
    "for name, model in models: \n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=seed) \n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, \n",
    "                                 scoring=scoring) \n",
    "    results.append(cv_results) \n",
    "    names.append(name) \n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()) \n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It looks like LR has the lowest MSE, followed closely by CART."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The differing scales of the data is probably hurting the skill of all of the algorithms and perhaps more so for SVR and KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Algorithms: Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We suspect that the differing scales of the raw data may be negatively impacting the skill of some of the algorithms. \n",
    "\n",
    "- Let’s evaluate the same algorithms with a standardized copy of the dataset. \n",
    "\n",
    "- This is where the data is transformed such that each attribute has a mean value of zero and a standard deviation of 1. \n",
    "\n",
    "- We also need to avoid data leakage when we transform the data. A good way to avoid leakage is to use pipelines that standardize the data and build the model for each fold in the cross validation test harness. That way we can get a fair estimation of how each model with standardized data might perform on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledLR: -22.006009 (12.188886)\n",
      "ScaledLASSO: -27.205896 (12.124418)\n",
      "ScaledEN: -28.301160 (13.609110)\n",
      "ScaledKNN: -21.456867 (15.016218)\n",
      "ScaledCART: -27.444731 (20.792120)\n",
      "ScaledSVR: -29.570433 (18.052964)\n"
     ]
    }
   ],
   "source": [
    "# Standardize the dataset \n",
    "\n",
    "pipelines = [] \n",
    "\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR', LinearRegression())]))) \n",
    "\n",
    "pipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()),('LASSO', Lasso())])))\n",
    "\n",
    "pipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()),('EN', ElasticNet())]))) \n",
    "\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsRegressor())]))) \n",
    "\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeRegressor())]))) \n",
    "\n",
    "pipelines.append(('ScaledSVR', Pipeline([('Scaler', StandardScaler()),('SVR', SVR())]))) \n",
    "\n",
    "\n",
    "results = [] \n",
    "\n",
    "names = []\n",
    "\n",
    "for name, model in pipelines: \n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=seed) \n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring) \n",
    "    results.append(cv_results) \n",
    "    names.append(name) \n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()) \n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can see that scaling did have an effect on KNN, driving the error lower than the other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve Results With Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We know from the results in the previous section that KNN achieves good results on a scaled version of the dataset. \n",
    "\n",
    "- But can it do better. The default value for the number of neighbors in KNN is 7. \n",
    "\n",
    "- We can use a grid search to try a set of different numbers of neighbors and see if we can improve the score. \n",
    "\n",
    "- The below example tries odd k values from 1 to 21, an arbitrary range covering a known good value of 7.\n",
    "\n",
    "- Each k value (n neighbors) is evaluated using 10-fold cross validation on a standardized copy of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Algorithm tuning \n",
    "scaler = StandardScaler().fit(X_train) \n",
    "rescaledX = scaler.transform(X_train) \n",
    "k_values = numpy.array([1,3,5,7,9,11,13,15,17,19,21]) \n",
    "param_grid = dict(n_neighbors=k_values) \n",
    "model = KNeighborsRegressor() \n",
    "kfold = KFold(n_splits=num_folds, shuffle = True,  random_state=seed) \n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold) \n",
    "grid_result = grid.fit(rescaledX, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display the mean and standard deviation scores as well as the best performing value for k below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001642</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "      <td>-6.551951</td>\n",
       "      <td>-12.080976</td>\n",
       "      <td>-18.283171</td>\n",
       "      <td>-55.252439</td>\n",
       "      <td>-44.741250</td>\n",
       "      <td>-14.083000</td>\n",
       "      <td>-7.249250</td>\n",
       "      <td>-14.713750</td>\n",
       "      <td>-10.341250</td>\n",
       "      <td>-11.681250</td>\n",
       "      <td>-19.497829</td>\n",
       "      <td>15.769847</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.013743</td>\n",
       "      <td>0.017976</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>-5.417398</td>\n",
       "      <td>-12.040840</td>\n",
       "      <td>-12.203496</td>\n",
       "      <td>-49.750352</td>\n",
       "      <td>-21.156750</td>\n",
       "      <td>-18.285222</td>\n",
       "      <td>-8.398583</td>\n",
       "      <td>-41.967250</td>\n",
       "      <td>-18.250111</td>\n",
       "      <td>-12.309833</td>\n",
       "      <td>-19.977984</td>\n",
       "      <td>13.803973</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.010630</td>\n",
       "      <td>0.019769</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>-6.689200</td>\n",
       "      <td>-13.748537</td>\n",
       "      <td>-11.067034</td>\n",
       "      <td>-53.469366</td>\n",
       "      <td>-16.311480</td>\n",
       "      <td>-23.128990</td>\n",
       "      <td>-8.341840</td>\n",
       "      <td>-44.845300</td>\n",
       "      <td>-19.970130</td>\n",
       "      <td>-15.137790</td>\n",
       "      <td>-21.270967</td>\n",
       "      <td>14.833544</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004567</td>\n",
       "      <td>0.008161</td>\n",
       "      <td>0.014131</td>\n",
       "      <td>0.018857</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>-6.226949</td>\n",
       "      <td>-16.080453</td>\n",
       "      <td>-13.279607</td>\n",
       "      <td>-58.129562</td>\n",
       "      <td>-15.010786</td>\n",
       "      <td>-20.217602</td>\n",
       "      <td>-9.320668</td>\n",
       "      <td>-39.061668</td>\n",
       "      <td>-24.372985</td>\n",
       "      <td>-14.072638</td>\n",
       "      <td>-21.577292</td>\n",
       "      <td>14.952592</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003391</td>\n",
       "      <td>0.004617</td>\n",
       "      <td>0.011619</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>9</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>-6.203695</td>\n",
       "      <td>-15.739524</td>\n",
       "      <td>-12.391415</td>\n",
       "      <td>-57.803207</td>\n",
       "      <td>-12.516963</td>\n",
       "      <td>-16.357120</td>\n",
       "      <td>-10.388645</td>\n",
       "      <td>-36.061574</td>\n",
       "      <td>-26.420846</td>\n",
       "      <td>-16.127762</td>\n",
       "      <td>-21.001075</td>\n",
       "      <td>14.701297</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.027205</td>\n",
       "      <td>0.052778</td>\n",
       "      <td>0.003214</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>11</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>-6.434511</td>\n",
       "      <td>-14.186432</td>\n",
       "      <td>-13.409528</td>\n",
       "      <td>-59.076954</td>\n",
       "      <td>-12.937095</td>\n",
       "      <td>-16.797285</td>\n",
       "      <td>-11.498723</td>\n",
       "      <td>-35.540364</td>\n",
       "      <td>-27.881556</td>\n",
       "      <td>-17.140614</td>\n",
       "      <td>-21.490306</td>\n",
       "      <td>14.866957</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.022990</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>13</td>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "      <td>-6.521080</td>\n",
       "      <td>-13.357483</td>\n",
       "      <td>-12.955943</td>\n",
       "      <td>-57.087088</td>\n",
       "      <td>-12.921959</td>\n",
       "      <td>-16.792902</td>\n",
       "      <td>-11.230528</td>\n",
       "      <td>-35.461266</td>\n",
       "      <td>-28.569882</td>\n",
       "      <td>-17.787197</td>\n",
       "      <td>-21.268533</td>\n",
       "      <td>14.454969</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003214</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.026555</td>\n",
       "      <td>0.039906</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "      <td>-7.060025</td>\n",
       "      <td>-14.583392</td>\n",
       "      <td>-12.974034</td>\n",
       "      <td>-56.414372</td>\n",
       "      <td>-13.541100</td>\n",
       "      <td>-17.364666</td>\n",
       "      <td>-11.405207</td>\n",
       "      <td>-36.529746</td>\n",
       "      <td>-29.482617</td>\n",
       "      <td>-20.325766</td>\n",
       "      <td>-21.968092</td>\n",
       "      <td>14.209894</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.010926</td>\n",
       "      <td>0.026930</td>\n",
       "      <td>0.045720</td>\n",
       "      <td>17</td>\n",
       "      <td>{'n_neighbors': 17}</td>\n",
       "      <td>-7.237698</td>\n",
       "      <td>-15.166675</td>\n",
       "      <td>-13.930354</td>\n",
       "      <td>-57.097560</td>\n",
       "      <td>-14.875633</td>\n",
       "      <td>-17.265716</td>\n",
       "      <td>-11.062323</td>\n",
       "      <td>-38.974785</td>\n",
       "      <td>-29.957401</td>\n",
       "      <td>-21.830653</td>\n",
       "      <td>-22.739880</td>\n",
       "      <td>14.492752</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003733</td>\n",
       "      <td>0.005605</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.024422</td>\n",
       "      <td>19</td>\n",
       "      <td>{'n_neighbors': 19}</td>\n",
       "      <td>-7.854025</td>\n",
       "      <td>-16.352230</td>\n",
       "      <td>-13.484398</td>\n",
       "      <td>-58.159597</td>\n",
       "      <td>-15.993613</td>\n",
       "      <td>-17.373455</td>\n",
       "      <td>-10.927091</td>\n",
       "      <td>-41.184154</td>\n",
       "      <td>-31.122860</td>\n",
       "      <td>-22.617582</td>\n",
       "      <td>-23.506901</td>\n",
       "      <td>14.903224</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.005883</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>0.017554</td>\n",
       "      <td>21</td>\n",
       "      <td>{'n_neighbors': 21}</td>\n",
       "      <td>-7.514332</td>\n",
       "      <td>-17.020356</td>\n",
       "      <td>-14.202556</td>\n",
       "      <td>-58.568162</td>\n",
       "      <td>-16.967947</td>\n",
       "      <td>-17.176474</td>\n",
       "      <td>-11.508211</td>\n",
       "      <td>-43.035752</td>\n",
       "      <td>-32.481244</td>\n",
       "      <td>-23.927996</td>\n",
       "      <td>-24.240303</td>\n",
       "      <td>15.156565</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.001642      0.000981         0.002126        0.000443   \n",
       "1        0.002366      0.001393         0.013743        0.017976   \n",
       "2        0.003921      0.003895         0.010630        0.019769   \n",
       "3        0.004567      0.008161         0.014131        0.018857   \n",
       "4        0.003391      0.004617         0.011619        0.011016   \n",
       "5        0.027205      0.052778         0.003214        0.001999   \n",
       "6        0.002034      0.002480         0.022990        0.054348   \n",
       "7        0.003214      0.003221         0.026555        0.039906   \n",
       "8        0.005361      0.010926         0.026930        0.045720   \n",
       "9        0.003733      0.005605         0.016358        0.024422   \n",
       "10       0.005883      0.011200         0.010636        0.017554   \n",
       "\n",
       "   param_n_neighbors               params  split0_test_score  \\\n",
       "0                  1   {'n_neighbors': 1}          -6.551951   \n",
       "1                  3   {'n_neighbors': 3}          -5.417398   \n",
       "2                  5   {'n_neighbors': 5}          -6.689200   \n",
       "3                  7   {'n_neighbors': 7}          -6.226949   \n",
       "4                  9   {'n_neighbors': 9}          -6.203695   \n",
       "5                 11  {'n_neighbors': 11}          -6.434511   \n",
       "6                 13  {'n_neighbors': 13}          -6.521080   \n",
       "7                 15  {'n_neighbors': 15}          -7.060025   \n",
       "8                 17  {'n_neighbors': 17}          -7.237698   \n",
       "9                 19  {'n_neighbors': 19}          -7.854025   \n",
       "10                21  {'n_neighbors': 21}          -7.514332   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0          -12.080976         -18.283171         -55.252439   \n",
       "1          -12.040840         -12.203496         -49.750352   \n",
       "2          -13.748537         -11.067034         -53.469366   \n",
       "3          -16.080453         -13.279607         -58.129562   \n",
       "4          -15.739524         -12.391415         -57.803207   \n",
       "5          -14.186432         -13.409528         -59.076954   \n",
       "6          -13.357483         -12.955943         -57.087088   \n",
       "7          -14.583392         -12.974034         -56.414372   \n",
       "8          -15.166675         -13.930354         -57.097560   \n",
       "9          -16.352230         -13.484398         -58.159597   \n",
       "10         -17.020356         -14.202556         -58.568162   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0          -44.741250         -14.083000          -7.249250   \n",
       "1          -21.156750         -18.285222          -8.398583   \n",
       "2          -16.311480         -23.128990          -8.341840   \n",
       "3          -15.010786         -20.217602          -9.320668   \n",
       "4          -12.516963         -16.357120         -10.388645   \n",
       "5          -12.937095         -16.797285         -11.498723   \n",
       "6          -12.921959         -16.792902         -11.230528   \n",
       "7          -13.541100         -17.364666         -11.405207   \n",
       "8          -14.875633         -17.265716         -11.062323   \n",
       "9          -15.993613         -17.373455         -10.927091   \n",
       "10         -16.967947         -17.176474         -11.508211   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0          -14.713750         -10.341250         -11.681250       -19.497829   \n",
       "1          -41.967250         -18.250111         -12.309833       -19.977984   \n",
       "2          -44.845300         -19.970130         -15.137790       -21.270967   \n",
       "3          -39.061668         -24.372985         -14.072638       -21.577292   \n",
       "4          -36.061574         -26.420846         -16.127762       -21.001075   \n",
       "5          -35.540364         -27.881556         -17.140614       -21.490306   \n",
       "6          -35.461266         -28.569882         -17.787197       -21.268533   \n",
       "7          -36.529746         -29.482617         -20.325766       -21.968092   \n",
       "8          -38.974785         -29.957401         -21.830653       -22.739880   \n",
       "9          -41.184154         -31.122860         -22.617582       -23.506901   \n",
       "10         -43.035752         -32.481244         -23.927996       -24.240303   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0        15.769847                1  \n",
       "1        13.803973                2  \n",
       "2        14.833544                5  \n",
       "3        14.952592                7  \n",
       "4        14.701297                3  \n",
       "5        14.866957                6  \n",
       "6        14.454969                4  \n",
       "7        14.209894                8  \n",
       "8        14.492752                9  \n",
       "9        14.903224               10  \n",
       "10       15.156565               11  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_result.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -19.497829 using {'n_neighbors': 1}\n",
      "-19.497829 (15.769847) with: {'n_neighbors': 1}\n",
      "-19.977984 (13.803973) with: {'n_neighbors': 3}\n",
      "-21.270967 (14.833544) with: {'n_neighbors': 5}\n",
      "-21.577292 (14.952592) with: {'n_neighbors': 7}\n",
      "-21.001075 (14.701297) with: {'n_neighbors': 9}\n",
      "-21.490306 (14.866957) with: {'n_neighbors': 11}\n",
      "-21.268533 (14.454969) with: {'n_neighbors': 13}\n",
      "-21.968092 (14.209894) with: {'n_neighbors': 15}\n",
      "-22.739880 (14.492752) with: {'n_neighbors': 17}\n",
      "-23.506901 (14.903224) with: {'n_neighbors': 19}\n",
      "-24.240303 (15.156565) with: {'n_neighbors': 21}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_)) \n",
    "means = grid_result.cv_results_['mean_test_score'] \n",
    "stds = grid_result.cv_results_['std_test_score'] \n",
    "params = grid_result.cv_results_['params'] \n",
    "for mean, stdev, param in zip(means, stds, params): \n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can see that the best for k (n neighbors) is 3 providing a mean squared error of -19.497829, the best so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way that we can improve the performance of algorithms on this problem is by using ensemble methods. In this section we will evaluate four different ensemble machine learning algorithms, two boosting and two bagging methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Boosting Methods: AdaBoost (AB) and Gradient Boosting (GBM). \n",
    "\n",
    "- Bagging Methods: Random Forests (RF) and Extra Trees (ET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same test harness as before, 10-fold cross validation and pipelines that standardize the training data for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledAB: -15.948952 (8.656773)\n",
      "ScaledGBM: -10.854067 (8.600890)\n",
      "ScaledRF: -12.836665 (10.004175)\n",
      "ScaledET: -9.127619 (6.471183)\n"
     ]
    }
   ],
   "source": [
    "# ensembles \n",
    "\n",
    "ensembles = [] \n",
    "\n",
    "ensembles.append(('ScaledAB', Pipeline([('Scaler', StandardScaler()),('AB', AdaBoostRegressor())]))) \n",
    "\n",
    "ensembles.append(('ScaledGBM', Pipeline([('Scaler', StandardScaler()),('GBM', GradientBoostingRegressor())]))) \n",
    "\n",
    "ensembles.append(('ScaledRF', Pipeline([('Scaler', StandardScaler()),('RF', RandomForestRegressor())]))) \n",
    "\n",
    "ensembles.append(('ScaledET', Pipeline([('Scaler', StandardScaler()),('ET', ExtraTreesRegressor())])))\n",
    "\n",
    "results = [] \n",
    "\n",
    "names = [] \n",
    "\n",
    "for name, model in ensembles: \n",
    "    kfold = KFold(n_splits=num_folds, shuffle = True,random_state=seed) \n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring) \n",
    "    results.append(cv_results) \n",
    "    names.append(name) \n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()) \n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we’re generally getting better scores than our linear and nonlinear algorithms in previous sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can probably do better, given that the ensemble techniques used the default parameters. In the next section we will look at tuning the Gradient Boosting to further lift the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The default number of boosting stages to perform (n estimators) is 100. \n",
    "  \n",
    "- This is a good candidate parameter of Gradient Boosting to tune. Often, the larger the number of boosting stages, the better the performance but the longer the training time. \n",
    "  \n",
    "- We will look at tuning the number of stages for gradient boosting. Below we define a parameter grid n estimators values from 50 to 400 in increments of 50. Each setting is evaluated using 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune scaled GBM \n",
    "# \n",
    "scaler = StandardScaler().fit(X_train) \n",
    "rescaledX = scaler.transform(X_train) \n",
    "param_grid = dict(n_estimators=numpy.array([50,100,150,200,250,300,350,400])) \n",
    "model = GradientBoostingRegressor(random_state=seed) \n",
    "kfold = KFold(n_splits=num_folds, shuffle = True, random_state=seed) \n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold) \n",
    "grid_result = grid.fit(rescaledX, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3]\n",
    "letters = ['a', 'b', 'c']\n",
    "zipped = zip(numbers, letters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x146866d40>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipped  # Holds an iterator object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'a'), (2, 'b'), (3, 'c')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.236267</td>\n",
       "      <td>0.092152</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>50</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>-5.481359</td>\n",
       "      <td>-10.927487</td>\n",
       "      <td>-6.573100</td>\n",
       "      <td>-36.642084</td>\n",
       "      <td>-7.435947</td>\n",
       "      <td>-7.071126</td>\n",
       "      <td>-6.717308</td>\n",
       "      <td>-16.113079</td>\n",
       "      <td>-9.175756</td>\n",
       "      <td>-10.162742</td>\n",
       "      <td>-11.629999</td>\n",
       "      <td>8.833221</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.461170</td>\n",
       "      <td>0.110094</td>\n",
       "      <td>0.007664</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>100</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "      <td>-5.412025</td>\n",
       "      <td>-10.563229</td>\n",
       "      <td>-6.579591</td>\n",
       "      <td>-36.089893</td>\n",
       "      <td>-7.822432</td>\n",
       "      <td>-6.909152</td>\n",
       "      <td>-6.827620</td>\n",
       "      <td>-15.436466</td>\n",
       "      <td>-6.730498</td>\n",
       "      <td>-8.363646</td>\n",
       "      <td>-11.073455</td>\n",
       "      <td>8.772155</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.133961</td>\n",
       "      <td>0.502632</td>\n",
       "      <td>0.009957</td>\n",
       "      <td>0.014930</td>\n",
       "      <td>150</td>\n",
       "      <td>{'n_estimators': 150}</td>\n",
       "      <td>-5.225549</td>\n",
       "      <td>-10.773407</td>\n",
       "      <td>-6.267163</td>\n",
       "      <td>-35.641099</td>\n",
       "      <td>-7.857168</td>\n",
       "      <td>-6.659527</td>\n",
       "      <td>-6.677740</td>\n",
       "      <td>-15.329910</td>\n",
       "      <td>-6.060382</td>\n",
       "      <td>-7.897297</td>\n",
       "      <td>-10.838924</td>\n",
       "      <td>8.734377</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.495328</td>\n",
       "      <td>0.606542</td>\n",
       "      <td>0.037595</td>\n",
       "      <td>0.059067</td>\n",
       "      <td>200</td>\n",
       "      <td>{'n_estimators': 200}</td>\n",
       "      <td>-5.464684</td>\n",
       "      <td>-10.617054</td>\n",
       "      <td>-6.399911</td>\n",
       "      <td>-35.584859</td>\n",
       "      <td>-7.820983</td>\n",
       "      <td>-6.694377</td>\n",
       "      <td>-6.779740</td>\n",
       "      <td>-14.565685</td>\n",
       "      <td>-6.007274</td>\n",
       "      <td>-7.921116</td>\n",
       "      <td>-10.785568</td>\n",
       "      <td>8.657244</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.895522</td>\n",
       "      <td>0.649625</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>250</td>\n",
       "      <td>{'n_estimators': 250}</td>\n",
       "      <td>-5.396245</td>\n",
       "      <td>-10.495517</td>\n",
       "      <td>-6.460672</td>\n",
       "      <td>-35.161702</td>\n",
       "      <td>-7.572761</td>\n",
       "      <td>-6.818321</td>\n",
       "      <td>-6.876358</td>\n",
       "      <td>-14.254981</td>\n",
       "      <td>-5.836170</td>\n",
       "      <td>-7.675051</td>\n",
       "      <td>-10.654778</td>\n",
       "      <td>8.540552</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.361415</td>\n",
       "      <td>0.679828</td>\n",
       "      <td>0.004916</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>300</td>\n",
       "      <td>{'n_estimators': 300}</td>\n",
       "      <td>-5.434832</td>\n",
       "      <td>-10.443748</td>\n",
       "      <td>-6.707328</td>\n",
       "      <td>-35.095466</td>\n",
       "      <td>-7.648669</td>\n",
       "      <td>-6.851895</td>\n",
       "      <td>-6.987611</td>\n",
       "      <td>-14.021441</td>\n",
       "      <td>-5.793195</td>\n",
       "      <td>-7.509668</td>\n",
       "      <td>-10.649385</td>\n",
       "      <td>8.497232</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.500523</td>\n",
       "      <td>0.454729</td>\n",
       "      <td>0.009325</td>\n",
       "      <td>0.011804</td>\n",
       "      <td>350</td>\n",
       "      <td>{'n_estimators': 350}</td>\n",
       "      <td>-5.436682</td>\n",
       "      <td>-10.349123</td>\n",
       "      <td>-6.723344</td>\n",
       "      <td>-34.782196</td>\n",
       "      <td>-7.578705</td>\n",
       "      <td>-6.738122</td>\n",
       "      <td>-7.089015</td>\n",
       "      <td>-13.996142</td>\n",
       "      <td>-5.747247</td>\n",
       "      <td>-7.452792</td>\n",
       "      <td>-10.589337</td>\n",
       "      <td>8.413596</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.493470</td>\n",
       "      <td>0.994899</td>\n",
       "      <td>0.011191</td>\n",
       "      <td>0.013217</td>\n",
       "      <td>400</td>\n",
       "      <td>{'n_estimators': 400}</td>\n",
       "      <td>-5.420766</td>\n",
       "      <td>-10.339825</td>\n",
       "      <td>-6.787734</td>\n",
       "      <td>-34.575777</td>\n",
       "      <td>-7.542901</td>\n",
       "      <td>-6.780063</td>\n",
       "      <td>-7.054276</td>\n",
       "      <td>-13.946617</td>\n",
       "      <td>-5.696099</td>\n",
       "      <td>-7.462319</td>\n",
       "      <td>-10.560638</td>\n",
       "      <td>8.353747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.236267      0.092152         0.004281        0.004285   \n",
       "1       0.461170      0.110094         0.007664        0.014586   \n",
       "2       1.133961      0.502632         0.009957        0.014930   \n",
       "3       2.495328      0.606542         0.037595        0.059067   \n",
       "4       1.895522      0.649625         0.004444        0.005659   \n",
       "5       2.361415      0.679828         0.004916        0.003386   \n",
       "6       3.500523      0.454729         0.009325        0.011804   \n",
       "7       4.493470      0.994899         0.011191        0.013217   \n",
       "\n",
       "  param_n_estimators                 params  split0_test_score  \\\n",
       "0                 50   {'n_estimators': 50}          -5.481359   \n",
       "1                100  {'n_estimators': 100}          -5.412025   \n",
       "2                150  {'n_estimators': 150}          -5.225549   \n",
       "3                200  {'n_estimators': 200}          -5.464684   \n",
       "4                250  {'n_estimators': 250}          -5.396245   \n",
       "5                300  {'n_estimators': 300}          -5.434832   \n",
       "6                350  {'n_estimators': 350}          -5.436682   \n",
       "7                400  {'n_estimators': 400}          -5.420766   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0         -10.927487          -6.573100         -36.642084          -7.435947   \n",
       "1         -10.563229          -6.579591         -36.089893          -7.822432   \n",
       "2         -10.773407          -6.267163         -35.641099          -7.857168   \n",
       "3         -10.617054          -6.399911         -35.584859          -7.820983   \n",
       "4         -10.495517          -6.460672         -35.161702          -7.572761   \n",
       "5         -10.443748          -6.707328         -35.095466          -7.648669   \n",
       "6         -10.349123          -6.723344         -34.782196          -7.578705   \n",
       "7         -10.339825          -6.787734         -34.575777          -7.542901   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0          -7.071126          -6.717308         -16.113079          -9.175756   \n",
       "1          -6.909152          -6.827620         -15.436466          -6.730498   \n",
       "2          -6.659527          -6.677740         -15.329910          -6.060382   \n",
       "3          -6.694377          -6.779740         -14.565685          -6.007274   \n",
       "4          -6.818321          -6.876358         -14.254981          -5.836170   \n",
       "5          -6.851895          -6.987611         -14.021441          -5.793195   \n",
       "6          -6.738122          -7.089015         -13.996142          -5.747247   \n",
       "7          -6.780063          -7.054276         -13.946617          -5.696099   \n",
       "\n",
       "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0         -10.162742       -11.629999        8.833221                8  \n",
       "1          -8.363646       -11.073455        8.772155                7  \n",
       "2          -7.897297       -10.838924        8.734377                6  \n",
       "3          -7.921116       -10.785568        8.657244                5  \n",
       "4          -7.675051       -10.654778        8.540552                4  \n",
       "5          -7.509668       -10.649385        8.497232                3  \n",
       "6          -7.452792       -10.589337        8.413596                2  \n",
       "7          -7.462319       -10.560638        8.353747                1  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_result.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.560637559010726"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -10.560638 using {'n_estimators': 400}\n",
      "(-11.629998657836461, 8.833221418068867, {'n_estimators': 50})\n",
      "(-11.073455273415261, 8.772154692069284, {'n_estimators': 100})\n",
      "(-10.838924199355183, 8.734377022610682, {'n_estimators': 150})\n",
      "(-10.78556829456355, 8.657244115563072, {'n_estimators': 200})\n",
      "(-10.65477776150534, 8.540551978773715, {'n_estimators': 250})\n",
      "(-10.649385465510363, 8.497232113066538, {'n_estimators': 300})\n",
      "(-10.589336898695533, 8.413596077609546, {'n_estimators': 350})\n",
      "(-10.560637559010726, 8.353747488148537, {'n_estimators': 400})\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_)) \n",
    "means = grid_result.cv_results_['mean_test_score'] \n",
    "stds = grid_result.cv_results_['std_test_score'] \n",
    "params = grid_result.cv_results_['params'] \n",
    "for mean, stdev, param in zip(means, stds, params): \n",
    "    print(f\"({mean}, {stdev}, {param})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best configuration was n estimators=400 resulting in a mean squared error of -10.560"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will finalize the gradient boosting model and evaluate it on our hold out validation dataset. First we need to prepare the model and train it on the entire training dataset. This includes standardizing the training dataset before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(n_estimators=400, random_state=7)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare the model \n",
    "scaler = StandardScaler().fit(X_train) \n",
    "rescaledX = scaler.transform(X_train) \n",
    "model = GradientBoostingRegressor(random_state=seed, n_estimators=400) \n",
    "model.fit(rescaledX, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then scale the inputs for the validation dataset and generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.902132586880027\n"
     ]
    }
   ],
   "source": [
    "# transform the validation dataset \n",
    " \n",
    "rescaledValidationX = scaler.transform(X_validation) \n",
    "predictions = model.predict(rescaledValidationX) \n",
    "print(mean_squared_error(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the estimated mean squared error is 11.9, close to our estimate of -10.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We worked through a regression predictive modeling machine learning problem from end-to-end using Python. Specifically, the steps covered were:  \n",
    "\n",
    "- Problem Definition (Boston house price data). \n",
    "  \n",
    "-  Loading the Dataset.  \n",
    "\n",
    "-  Analyze Data (some skewed distributions and correlated attributes).  \n",
    "\n",
    "-  Evaluate Algorithms (Linear Regression looked good).  \n",
    "\n",
    "-  Evaluate Algorithms with Standardization (KNN looked good). \n",
    "\n",
    "-  Algorithm Tuning (K=3 for KNN was best).  \n",
    "\n",
    "-  Ensemble Methods (Bagging and Boosting, Gradient Boosting looked good). \n",
    "\n",
    "-  Tuning Ensemble Methods (getting the most from Gradient Boosting). \n",
    "\n",
    "-  Finalize Model (use all training data and confirm using validation dataset). \n",
    "\n",
    "-  Working through this case study showed you how the recipes for specific machine learning tasks can be pulled together into a complete project. Working through this case study is good practice at applied machine learning using Python and scikit-learn."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "895aa688263384567493505d09875376e7685297a6922210da729f70c5caa3cf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('datascience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
